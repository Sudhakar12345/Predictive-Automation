17/02/16 10:22:01 INFO SparkContext: Running Spark version 2.0.0
17/02/16 10:22:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/02/16 10:22:03 INFO SecurityManager: Changing view acls to: vinayak
17/02/16 10:22:03 INFO SecurityManager: Changing modify acls to: vinayak
17/02/16 10:22:03 INFO SecurityManager: Changing view acls groups to: 
17/02/16 10:22:03 INFO SecurityManager: Changing modify acls groups to: 
17/02/16 10:22:03 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(vinayak); groups with view permissions: Set(); users  with modify permissions: Set(vinayak); groups with modify permissions: Set()
17/02/16 10:22:03 INFO Utils: Successfully started service 'sparkDriver' on port 51287.
17/02/16 10:22:03 INFO SparkEnv: Registering MapOutputTracker
17/02/16 10:22:03 INFO SparkEnv: Registering BlockManagerMaster
17/02/16 10:22:03 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-5a742cfa-fece-4187-b680-e87bdeb23e5c
17/02/16 10:22:03 INFO MemoryStore: MemoryStore started with capacity 366.1 MB
17/02/16 10:22:03 INFO SparkEnv: Registering OutputCommitCoordinator
17/02/16 10:22:04 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/02/16 10:22:04 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
17/02/16 10:22:04 INFO SparkContext: Added JAR file:/home/vinayak/R/i686-pc-linux-gnu-library/3.3/sparklyr/java/sparklyr-2.0-2.11.jar at spark://127.0.0.1:51287/jars/sparklyr-2.0-2.11.jar with timestamp 1487220724588
17/02/16 10:22:04 INFO Executor: Starting executor ID driver on host localhost
17/02/16 10:22:04 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53689.
17/02/16 10:22:04 INFO NettyBlockTransferService: Server created on 127.0.0.1:53689
17/02/16 10:22:04 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 53689)
17/02/16 10:22:04 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:53689 with 366.1 MB RAM, BlockManagerId(driver, 127.0.0.1, 53689)
17/02/16 10:22:04 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 53689)
17/02/16 10:22:05 WARN SparkContext: Use an existing SparkContext, some configuration may not take effect.
17/02/16 10:22:05 WARN SparkContext: Use an existing SparkContext, some configuration may not take effect.
17/02/16 10:22:05 INFO HiveSharedState: Warehouse path is 'file:/home/vinayak/sudhakar/R/automation_model/spark-warehouse'.
17/02/16 10:24:14 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/02/16 10:24:16 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
17/02/16 10:24:18 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
17/02/16 10:24:18 INFO ObjectStore: ObjectStore, initialize called
17/02/16 10:24:18 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
17/02/16 10:24:18 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
17/02/16 10:24:21 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
17/02/16 10:24:22 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/02/16 10:24:22 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/02/16 10:24:23 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/02/16 10:24:23 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/02/16 10:24:23 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
17/02/16 10:24:23 INFO ObjectStore: Initialized ObjectStore
17/02/16 10:24:23 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
17/02/16 10:24:23 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
17/02/16 10:24:24 INFO HiveMetaStore: Added admin role in metastore
17/02/16 10:24:24 INFO HiveMetaStore: Added public role in metastore
17/02/16 10:24:24 INFO HiveMetaStore: No user is added in admin role, since config is empty
17/02/16 10:24:24 INFO HiveMetaStore: 0: get_all_databases
17/02/16 10:24:24 INFO audit: ugi=vinayak	ip=unknown-ip-addr	cmd=get_all_databases	
17/02/16 10:24:24 INFO HiveMetaStore: 0: get_functions: db=default pat=*
17/02/16 10:24:24 INFO audit: ugi=vinayak	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
17/02/16 10:24:24 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
17/02/16 10:24:25 INFO SessionState: Created HDFS directory: /tmp/hive/vinayak
17/02/16 10:24:25 INFO SessionState: Created local directory: /tmp/vinayak
17/02/16 10:24:25 INFO SessionState: Created local directory: /tmp/2ac15507-4036-431d-872f-22a505b4b216_resources
17/02/16 10:24:25 INFO SessionState: Created HDFS directory: /tmp/hive/vinayak/2ac15507-4036-431d-872f-22a505b4b216
17/02/16 10:24:25 INFO SessionState: Created local directory: /tmp/vinayak/2ac15507-4036-431d-872f-22a505b4b216
17/02/16 10:24:25 INFO SessionState: Created HDFS directory: /tmp/hive/vinayak/2ac15507-4036-431d-872f-22a505b4b216/_tmp_space.db
17/02/16 10:24:25 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/home/vinayak/sudhakar/R/automation_model/spark-warehouse
17/02/16 10:24:25 INFO SessionState: Created local directory: /tmp/29f05f92-23bc-4c09-850b-5009f3ad8c63_resources
17/02/16 10:24:25 INFO SessionState: Created HDFS directory: /tmp/hive/vinayak/29f05f92-23bc-4c09-850b-5009f3ad8c63
17/02/16 10:24:25 INFO SessionState: Created local directory: /tmp/vinayak/29f05f92-23bc-4c09-850b-5009f3ad8c63
17/02/16 10:24:25 INFO SessionState: Created HDFS directory: /tmp/hive/vinayak/29f05f92-23bc-4c09-850b-5009f3ad8c63/_tmp_space.db
17/02/16 10:24:25 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/home/vinayak/sudhakar/R/automation_model/spark-warehouse
17/02/16 10:24:25 INFO HiveMetaStore: 0: create_database: Database(name:default, description:default database, locationUri:file:/home/vinayak/sudhakar/R/automation_model/spark-warehouse, parameters:{})
17/02/16 10:24:25 INFO audit: ugi=vinayak	ip=unknown-ip-addr	cmd=create_database: Database(name:default, description:default database, locationUri:file:/home/vinayak/sudhakar/R/automation_model/spark-warehouse, parameters:{})	
17/02/16 10:24:26 INFO HiveMetaStore: 0: get_database: default
17/02/16 10:24:26 INFO audit: ugi=vinayak	ip=unknown-ip-addr	cmd=get_database: default	
17/02/16 10:24:26 INFO HiveMetaStore: 0: get_database: default
17/02/16 10:24:26 INFO audit: ugi=vinayak	ip=unknown-ip-addr	cmd=get_database: default	
17/02/16 10:24:26 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/02/16 10:24:26 INFO audit: ugi=vinayak	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/02/16 10:24:27 INFO CodeGenerator: Code generated in 431.889257 ms
17/02/16 10:24:28 INFO SparkContext: Starting job: collect at utils.scala:59
17/02/16 10:24:28 INFO DAGScheduler: Got job 0 (collect at utils.scala:59) with 1 output partitions
17/02/16 10:24:28 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:59)
17/02/16 10:24:28 INFO DAGScheduler: Parents of final stage: List()
17/02/16 10:24:28 INFO DAGScheduler: Missing parents: List()
17/02/16 10:24:28 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[5] at map at utils.scala:56), which has no missing parents
17/02/16 10:24:28 WARN SizeEstimator: Failed to check whether UseCompressedOops is set; assuming yes
17/02/16 10:24:28 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.3 KB, free 366.1 MB)
17/02/16 10:24:28 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.4 KB, free 366.1 MB)
17/02/16 10:24:28 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:53689 (size: 4.4 KB, free: 366.1 MB)
17/02/16 10:24:28 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1012
17/02/16 10:24:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at map at utils.scala:56)
17/02/16 10:24:28 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
17/02/16 10:24:28 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5414 bytes)
17/02/16 10:24:28 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/02/16 10:24:28 INFO Executor: Fetching spark://127.0.0.1:51287/jars/sparklyr-2.0-2.11.jar with timestamp 1487220724588
17/02/16 10:24:28 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:51287 after 18 ms (0 ms spent in bootstraps)
17/02/16 10:24:28 INFO Utils: Fetching spark://127.0.0.1:51287/jars/sparklyr-2.0-2.11.jar to /tmp/spark-d50e46bc-9e28-4b0e-b883-3a68be0516e0/userFiles-4a9c66e1-d0c3-4c7b-b792-9ce352f1cdb1/fetchFileTemp6349681360520661492.tmp
17/02/16 10:24:29 INFO Executor: Adding file:/tmp/spark-d50e46bc-9e28-4b0e-b883-3a68be0516e0/userFiles-4a9c66e1-d0c3-4c7b-b792-9ce352f1cdb1/sparklyr-2.0-2.11.jar to class loader
17/02/16 10:24:29 INFO CodeGenerator: Code generated in 16.609241 ms
17/02/16 10:24:29 INFO CodeGenerator: Code generated in 36.843718 ms
17/02/16 10:24:29 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1062 bytes result sent to driver
17/02/16 10:24:29 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 682 ms on localhost (1/1)
17/02/16 10:24:29 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/02/16 10:24:29 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:59) finished in 0.738 s
17/02/16 10:24:29 INFO DAGScheduler: Job 0 finished: collect at utils.scala:59, took 1.103228 s
17/02/16 10:24:29 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 64.6 KB, free 366.1 MB)
17/02/16 10:24:29 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 22.9 KB, free 366.1 MB)
17/02/16 10:24:29 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:53689 (size: 22.9 KB, free: 366.1 MB)
17/02/16 10:24:29 INFO SparkContext: Created broadcast 1 from csv at NativeMethodAccessorImpl.java:-2
17/02/16 10:24:30 INFO FileInputFormat: Total input paths to process : 1
17/02/16 10:24:30 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:-2
17/02/16 10:24:30 INFO DAGScheduler: Got job 1 (csv at NativeMethodAccessorImpl.java:-2) with 1 output partitions
17/02/16 10:24:30 INFO DAGScheduler: Final stage: ResultStage 1 (csv at NativeMethodAccessorImpl.java:-2)
17/02/16 10:24:30 INFO DAGScheduler: Parents of final stage: List()
17/02/16 10:24:30 INFO DAGScheduler: Missing parents: List()
17/02/16 10:24:30 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[8] at csv at NativeMethodAccessorImpl.java:-2), which has no missing parents
17/02/16 10:24:30 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 3.4 KB, free 366.0 MB)
17/02/16 10:24:30 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.0 KB, free 366.0 MB)
17/02/16 10:24:30 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:53689 (size: 2.0 KB, free: 366.1 MB)
17/02/16 10:24:30 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1012
17/02/16 10:24:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at csv at NativeMethodAccessorImpl.java:-2)
17/02/16 10:24:30 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
17/02/16 10:24:30 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5502 bytes)
17/02/16 10:24:30 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
17/02/16 10:24:30 INFO HadoopRDD: Input split: file:/tmp/RtmpWFoxD2/spark_serialize_61b85414fcdf09387c0ad9dc28e430dfd545d5b9c811118fc1cd89a82db551e3.csv:0+2317
17/02/16 10:24:30 INFO deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
17/02/16 10:24:30 INFO deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
17/02/16 10:24:30 INFO deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
17/02/16 10:24:30 INFO deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
17/02/16 10:24:30 INFO deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
17/02/16 10:24:30 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 995 bytes result sent to driver
17/02/16 10:24:30 INFO DAGScheduler: ResultStage 1 (csv at NativeMethodAccessorImpl.java:-2) finished in 0.190 s
17/02/16 10:24:30 INFO DAGScheduler: Job 1 finished: csv at NativeMethodAccessorImpl.java:-2, took 0.202008 s
17/02/16 10:24:30 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 190 ms on localhost (1/1)
17/02/16 10:24:30 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/02/16 10:24:30 INFO ContextCleaner: Cleaned accumulator 1
17/02/16 10:24:30 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 209.0 KB, free 365.8 MB)
17/02/16 10:24:30 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 22.9 KB, free 365.8 MB)
17/02/16 10:24:30 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:53689 (size: 22.9 KB, free: 366.1 MB)
17/02/16 10:24:30 INFO SparkContext: Created broadcast 3 from csv at NativeMethodAccessorImpl.java:-2
17/02/16 10:24:30 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:53689 in memory (size: 4.4 KB, free: 366.1 MB)
17/02/16 10:24:30 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:53689 in memory (size: 2.0 KB, free: 366.1 MB)
17/02/16 10:24:30 INFO ContextCleaner: Cleaned accumulator 0
17/02/16 10:24:30 INFO SparkSqlParser: Parsing command: iris
17/02/16 10:24:30 INFO SparkSqlParser: Parsing command: CACHE TABLE `iris`
17/02/16 10:24:30 INFO SparkSqlParser: Parsing command: `iris`
17/02/16 10:24:30 INFO FileSourceStrategy: Pruning directories with: 
17/02/16 10:24:30 INFO FileSourceStrategy: Post-Scan Filters: 
17/02/16 10:24:30 INFO FileSourceStrategy: Pruned Data Schema: struct<Sepal_Length: string, Sepal_Width: double, Petal_Length: double, Petal_Width: double, Species: string ... 1 more field>
17/02/16 10:24:30 INFO FileSourceStrategy: Pushed Filters: 
17/02/16 10:24:30 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 242.6 KB, free 365.6 MB)
17/02/16 10:24:30 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 23.4 KB, free 365.6 MB)
17/02/16 10:24:30 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:53689 (size: 23.4 KB, free: 366.1 MB)
17/02/16 10:24:30 INFO SparkContext: Created broadcast 4 from sql at NativeMethodAccessorImpl.java:-2
17/02/16 10:24:30 INFO FileSourceStrategy: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/02/16 10:24:31 INFO CodeGenerator: Code generated in 8.129987 ms
17/02/16 10:24:31 INFO CodeGenerator: Code generated in 31.783939 ms
17/02/16 10:24:31 INFO CodeGenerator: Code generated in 13.460872 ms
17/02/16 10:24:31 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:-2
17/02/16 10:24:31 INFO DAGScheduler: Registering RDD 18 (sql at NativeMethodAccessorImpl.java:-2)
17/02/16 10:24:31 INFO DAGScheduler: Got job 2 (sql at NativeMethodAccessorImpl.java:-2) with 1 output partitions
17/02/16 10:24:31 INFO DAGScheduler: Final stage: ResultStage 3 (sql at NativeMethodAccessorImpl.java:-2)
17/02/16 10:24:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
17/02/16 10:24:31 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
17/02/16 10:24:31 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[18] at sql at NativeMethodAccessorImpl.java:-2), which has no missing parents
17/02/16 10:24:31 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 17.0 KB, free 365.6 MB)
17/02/16 10:24:31 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 7.9 KB, free 365.6 MB)
17/02/16 10:24:31 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:53689 (size: 7.9 KB, free: 366.1 MB)
17/02/16 10:24:31 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1012
17/02/16 10:24:31 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[18] at sql at NativeMethodAccessorImpl.java:-2)
17/02/16 10:24:31 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
17/02/16 10:24:31 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5989 bytes)
17/02/16 10:24:31 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
17/02/16 10:24:31 INFO FileScanRDD: Reading File path: file:///tmp/RtmpWFoxD2/spark_serialize_61b85414fcdf09387c0ad9dc28e430dfd545d5b9c811118fc1cd89a82db551e3.csv, range: 0-4635, partition values: [empty row]
17/02/16 10:24:31 INFO CodeGenerator: Code generated in 13.976344 ms
17/02/16 10:24:31 INFO MemoryStore: Block rdd_15_0 stored as values in memory (estimated size 5.2 KB, free 365.5 MB)
17/02/16 10:24:31 INFO BlockManagerInfo: Added rdd_15_0 in memory on 127.0.0.1:53689 (size: 5.2 KB, free: 366.1 MB)
17/02/16 10:24:31 INFO CodeGenerator: Code generated in 5.846068 ms
17/02/16 10:24:31 INFO CodeGenerator: Code generated in 42.658709 ms
17/02/16 10:24:31 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 3620 bytes result sent to driver
17/02/16 10:24:31 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 377 ms on localhost (1/1)
17/02/16 10:24:31 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/02/16 10:24:31 INFO DAGScheduler: ShuffleMapStage 2 (sql at NativeMethodAccessorImpl.java:-2) finished in 0.378 s
17/02/16 10:24:31 INFO DAGScheduler: looking for newly runnable stages
17/02/16 10:24:31 INFO DAGScheduler: running: Set()
17/02/16 10:24:31 INFO DAGScheduler: waiting: Set(ResultStage 3)
17/02/16 10:24:31 INFO DAGScheduler: failed: Set()
17/02/16 10:24:31 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[21] at sql at NativeMethodAccessorImpl.java:-2), which has no missing parents
17/02/16 10:24:31 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 7.0 KB, free 365.5 MB)
17/02/16 10:24:31 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.7 KB, free 365.5 MB)
17/02/16 10:24:31 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:53689 (size: 3.7 KB, free: 366.1 MB)
17/02/16 10:24:31 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1012
17/02/16 10:24:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[21] at sql at NativeMethodAccessorImpl.java:-2)
17/02/16 10:24:31 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
17/02/16 10:24:31 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, ANY, 5343 bytes)
17/02/16 10:24:31 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
17/02/16 10:24:31 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/02/16 10:24:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
17/02/16 10:24:32 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1873 bytes result sent to driver
17/02/16 10:24:32 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 108 ms on localhost (1/1)
17/02/16 10:24:32 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/02/16 10:24:32 INFO DAGScheduler: ResultStage 3 (sql at NativeMethodAccessorImpl.java:-2) finished in 0.109 s
17/02/16 10:24:32 INFO DAGScheduler: Job 2 finished: sql at NativeMethodAccessorImpl.java:-2, took 0.574764 s
17/02/16 10:24:32 INFO CodeGenerator: Code generated in 9.477183 ms
17/02/16 10:24:32 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `iris`
17/02/16 10:24:32 INFO SparkSqlParser: Parsing command: count(1)
17/02/16 10:24:32 INFO CodeGenerator: Code generated in 16.933082 ms
17/02/16 10:24:32 INFO CodeGenerator: Code generated in 10.193062 ms
17/02/16 10:24:32 INFO SparkContext: Starting job: collect at utils.scala:195
17/02/16 10:24:32 INFO DAGScheduler: Registering RDD 25 (collect at utils.scala:195)
17/02/16 10:24:32 INFO DAGScheduler: Got job 3 (collect at utils.scala:195) with 1 output partitions
17/02/16 10:24:32 INFO DAGScheduler: Final stage: ResultStage 5 (collect at utils.scala:195)
17/02/16 10:24:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
17/02/16 10:24:32 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 4)
17/02/16 10:24:32 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[25] at collect at utils.scala:195), which has no missing parents
17/02/16 10:24:32 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 16.2 KB, free 365.5 MB)
17/02/16 10:24:32 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 7.6 KB, free 365.5 MB)
17/02/16 10:24:32 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:53689 (size: 7.6 KB, free: 366.1 MB)
17/02/16 10:24:32 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1012
17/02/16 10:24:32 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[25] at collect at utils.scala:195)
17/02/16 10:24:32 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
17/02/16 10:24:32 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5981 bytes)
17/02/16 10:24:32 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
17/02/16 10:24:32 INFO BlockManager: Found block rdd_15_0 locally
17/02/16 10:24:32 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 2141 bytes result sent to driver
17/02/16 10:24:32 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 53 ms on localhost (1/1)
17/02/16 10:24:32 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
17/02/16 10:24:32 INFO DAGScheduler: ShuffleMapStage 4 (collect at utils.scala:195) finished in 0.055 s
17/02/16 10:24:32 INFO DAGScheduler: looking for newly runnable stages
17/02/16 10:24:32 INFO DAGScheduler: running: Set()
17/02/16 10:24:32 INFO DAGScheduler: waiting: Set(ResultStage 5)
17/02/16 10:24:32 INFO DAGScheduler: failed: Set()
17/02/16 10:24:32 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[28] at collect at utils.scala:195), which has no missing parents
17/02/16 10:24:32 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 9.5 KB, free 365.5 MB)
17/02/16 10:24:32 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 4.1 KB, free 365.5 MB)
17/02/16 10:24:32 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:53689 (size: 4.1 KB, free: 366.1 MB)
17/02/16 10:24:32 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1012
17/02/16 10:24:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[28] at collect at utils.scala:195)
17/02/16 10:24:32 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
17/02/16 10:24:32 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, ANY, 5335 bytes)
17/02/16 10:24:32 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
17/02/16 10:24:32 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/02/16 10:24:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/02/16 10:24:32 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 2189 bytes result sent to driver
17/02/16 10:24:32 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 9 ms on localhost (1/1)
17/02/16 10:24:32 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/02/16 10:24:32 INFO DAGScheduler: ResultStage 5 (collect at utils.scala:195) finished in 0.009 s
17/02/16 10:24:32 INFO DAGScheduler: Job 3 finished: collect at utils.scala:195, took 0.084725 s
17/02/16 10:24:32 INFO SparkSqlParser: Parsing command: SELECT *
FROM `iris` AS `zzz1`
WHERE (0 = 1)
17/02/16 10:24:32 INFO SparkSqlParser: Parsing command: Sepal_Length
17/02/16 10:24:32 INFO SparkSqlParser: Parsing command: Sepal_Width
17/02/16 10:24:32 INFO SparkSqlParser: Parsing command: Petal_Length
17/02/16 10:24:32 INFO SparkSqlParser: Parsing command: Petal_Width
17/02/16 10:24:32 INFO SparkSqlParser: Parsing command: Species
17/02/16 10:24:32 INFO SparkSqlParser: Parsing command: clster
17/02/16 10:24:37 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/02/16 10:24:37 INFO HiveMetaStore: 0: get_database: default
17/02/16 10:24:37 INFO audit: ugi=vinayak	ip=unknown-ip-addr	cmd=get_database: default	
17/02/16 10:24:37 INFO HiveMetaStore: 0: get_database: default
17/02/16 10:24:37 INFO audit: ugi=vinayak	ip=unknown-ip-addr	cmd=get_database: default	
17/02/16 10:24:37 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/02/16 10:24:37 INFO audit: ugi=vinayak	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/02/16 10:24:37 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:53689 in memory (size: 3.7 KB, free: 366.1 MB)
17/02/16 10:24:37 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:53689 in memory (size: 7.6 KB, free: 366.1 MB)
17/02/16 10:24:37 INFO SparkContext: Starting job: collect at utils.scala:59
17/02/16 10:24:37 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:53689 in memory (size: 4.1 KB, free: 366.1 MB)
17/02/16 10:24:37 INFO DAGScheduler: Got job 4 (collect at utils.scala:59) with 1 output partitions
17/02/16 10:24:37 INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:59)
17/02/16 10:24:37 INFO DAGScheduler: Parents of final stage: List()
17/02/16 10:24:37 INFO DAGScheduler: Missing parents: List()
17/02/16 10:24:37 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[34] at map at utils.scala:56), which has no missing parents
17/02/16 10:24:37 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 8.3 KB, free 365.5 MB)
17/02/16 10:24:37 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 4.4 KB, free 365.5 MB)
17/02/16 10:24:37 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:53689 (size: 4.4 KB, free: 366.1 MB)
17/02/16 10:24:37 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:53689 in memory (size: 7.9 KB, free: 366.1 MB)
17/02/16 10:24:37 INFO ContextCleaner: Cleaned accumulator 194
17/02/16 10:24:37 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1012
17/02/16 10:24:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[34] at map at utils.scala:56)
17/02/16 10:24:37 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
17/02/16 10:24:37 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:53689 in memory (size: 22.9 KB, free: 366.1 MB)
17/02/16 10:24:37 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0, PROCESS_LOCAL, 5683 bytes)
17/02/16 10:24:37 INFO ContextCleaner: Cleaned accumulator 93
17/02/16 10:24:37 INFO ContextCleaner: Cleaned accumulator 94
17/02/16 10:24:37 INFO ContextCleaner: Cleaned accumulator 95
17/02/16 10:24:37 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
17/02/16 10:24:37 INFO ContextCleaner: Cleaned accumulator 96
17/02/16 10:24:37 INFO ContextCleaner: Cleaned accumulator 97
17/02/16 10:24:37 INFO ContextCleaner: Cleaned accumulator 98
17/02/16 10:24:37 INFO ContextCleaner: Cleaned accumulator 99
17/02/16 10:24:37 INFO ContextCleaner: Cleaned accumulator 100
17/02/16 10:24:37 INFO ContextCleaner: Cleaned accumulator 101
17/02/16 10:24:37 INFO ContextCleaner: Cleaned accumulator 102
17/02/16 10:24:37 INFO ContextCleaner: Cleaned accumulator 103
17/02/16 10:24:37 INFO ContextCleaner: Cleaned accumulator 104
17/02/16 10:24:37 INFO ContextCleaner: Cleaned accumulator 105
17/02/16 10:24:37 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1069 bytes result sent to driver
17/02/16 10:24:37 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 10 ms on localhost (1/1)
17/02/16 10:24:37 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
17/02/16 10:24:37 INFO DAGScheduler: ResultStage 6 (collect at utils.scala:59) finished in 0.011 s
17/02/16 10:24:37 INFO DAGScheduler: Job 4 finished: collect at utils.scala:59, took 0.020887 s
17/02/16 10:24:37 INFO ContextCleaner: Cleaned shuffle 0
17/02/16 10:24:45 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 209.0 KB, free 365.6 MB)
17/02/16 10:24:45 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 22.9 KB, free 365.6 MB)
17/02/16 10:24:45 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:53689 (size: 22.9 KB, free: 366.1 MB)
17/02/16 10:24:45 INFO SparkContext: Created broadcast 10 from csv at NativeMethodAccessorImpl.java:-2
17/02/16 10:24:45 INFO FileInputFormat: Total input paths to process : 1
17/02/16 10:24:45 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:-2
17/02/16 10:24:45 INFO DAGScheduler: Got job 5 (csv at NativeMethodAccessorImpl.java:-2) with 1 output partitions
17/02/16 10:24:45 INFO DAGScheduler: Final stage: ResultStage 7 (csv at NativeMethodAccessorImpl.java:-2)
17/02/16 10:24:45 INFO DAGScheduler: Parents of final stage: List()
17/02/16 10:24:45 INFO DAGScheduler: Missing parents: List()
17/02/16 10:24:45 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[37] at csv at NativeMethodAccessorImpl.java:-2), which has no missing parents
17/02/16 10:24:45 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 3.4 KB, free 365.6 MB)
17/02/16 10:24:45 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 2.0 KB, free 365.6 MB)
17/02/16 10:24:45 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:53689 (size: 2.0 KB, free: 366.1 MB)
17/02/16 10:24:45 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1012
17/02/16 10:24:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[37] at csv at NativeMethodAccessorImpl.java:-2)
17/02/16 10:24:45 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
17/02/16 10:24:45 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, partition 0, PROCESS_LOCAL, 5502 bytes)
17/02/16 10:24:45 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
17/02/16 10:24:45 INFO HadoopRDD: Input split: file:/tmp/RtmpWFoxD2/spark_serialize_bdf64b31db10334a157167e3720fb5fda677e92a85e2e167238fb89c721869ff.csv:0+16656553
17/02/16 10:24:45 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 1114 bytes result sent to driver
17/02/16 10:24:45 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 10 ms on localhost (1/1)
17/02/16 10:24:45 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
17/02/16 10:24:45 INFO DAGScheduler: ResultStage 7 (csv at NativeMethodAccessorImpl.java:-2) finished in 0.004 s
17/02/16 10:24:45 INFO DAGScheduler: Job 5 finished: csv at NativeMethodAccessorImpl.java:-2, took 0.018519 s
17/02/16 10:24:45 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 209.0 KB, free 365.4 MB)
17/02/16 10:24:45 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 22.9 KB, free 365.3 MB)
17/02/16 10:24:45 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:53689 (size: 22.9 KB, free: 366.0 MB)
17/02/16 10:24:45 INFO SparkContext: Created broadcast 12 from csv at NativeMethodAccessorImpl.java:-2
17/02/16 10:24:45 INFO SparkSqlParser: Parsing command: flights
17/02/16 10:24:45 INFO SparkSqlParser: Parsing command: CACHE TABLE `flights`
17/02/16 10:24:45 INFO SparkSqlParser: Parsing command: `flights`
17/02/16 10:24:45 INFO FileSourceStrategy: Pruning directories with: 
17/02/16 10:24:45 INFO FileSourceStrategy: Post-Scan Filters: 
17/02/16 10:24:45 INFO FileSourceStrategy: Pruned Data Schema: struct<year: int, month: int, day: int, dep_time: int, sched_dep_time: int ... 17 more fields>
17/02/16 10:24:45 INFO FileSourceStrategy: Pushed Filters: 
17/02/16 10:24:45 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 242.6 KB, free 365.1 MB)
17/02/16 10:24:45 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 23.4 KB, free 365.1 MB)
17/02/16 10:24:45 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:53689 (size: 23.4 KB, free: 366.0 MB)
17/02/16 10:24:45 INFO SparkContext: Created broadcast 13 from sql at NativeMethodAccessorImpl.java:-2
17/02/16 10:24:45 INFO FileSourceStrategy: Planning scan with bin packing, max size: 9376852 bytes, open cost is considered as scanning 4194304 bytes.
17/02/16 10:24:45 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:-2
17/02/16 10:24:45 INFO DAGScheduler: Registering RDD 47 (sql at NativeMethodAccessorImpl.java:-2)
17/02/16 10:24:45 INFO DAGScheduler: Got job 6 (sql at NativeMethodAccessorImpl.java:-2) with 1 output partitions
17/02/16 10:24:45 INFO DAGScheduler: Final stage: ResultStage 9 (sql at NativeMethodAccessorImpl.java:-2)
17/02/16 10:24:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
17/02/16 10:24:45 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 8)
17/02/16 10:24:45 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[47] at sql at NativeMethodAccessorImpl.java:-2), which has no missing parents
17/02/16 10:24:45 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 25.0 KB, free 365.0 MB)
17/02/16 10:24:45 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 10.2 KB, free 365.0 MB)
17/02/16 10:24:45 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:53689 (size: 10.2 KB, free: 366.0 MB)
17/02/16 10:24:45 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1012
17/02/16 10:24:45 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[47] at sql at NativeMethodAccessorImpl.java:-2)
17/02/16 10:24:45 INFO TaskSchedulerImpl: Adding task set 8.0 with 4 tasks
17/02/16 10:24:45 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, partition 0, PROCESS_LOCAL, 5989 bytes)
17/02/16 10:24:45 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 9, localhost, partition 1, PROCESS_LOCAL, 5989 bytes)
17/02/16 10:24:45 INFO TaskSetManager: Starting task 2.0 in stage 8.0 (TID 10, localhost, partition 2, PROCESS_LOCAL, 5989 bytes)
17/02/16 10:24:45 INFO TaskSetManager: Starting task 3.0 in stage 8.0 (TID 11, localhost, partition 3, PROCESS_LOCAL, 5989 bytes)
17/02/16 10:24:45 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
17/02/16 10:24:45 INFO FileScanRDD: Reading File path: file:///tmp/RtmpWFoxD2/spark_serialize_bdf64b31db10334a157167e3720fb5fda677e92a85e2e167238fb89c721869ff.csv, range: 0-9376852, partition values: [empty row]
17/02/16 10:24:45 INFO Executor: Running task 1.0 in stage 8.0 (TID 9)
17/02/16 10:24:45 INFO Executor: Running task 3.0 in stage 8.0 (TID 11)
17/02/16 10:24:45 INFO Executor: Running task 2.0 in stage 8.0 (TID 10)
17/02/16 10:24:45 INFO FileScanRDD: Reading File path: file:///tmp/RtmpWFoxD2/spark_serialize_bdf64b31db10334a157167e3720fb5fda677e92a85e2e167238fb89c721869ff.csv, range: 9376852-18753704, partition values: [empty row]
17/02/16 10:24:45 INFO FileScanRDD: Reading File path: file:///tmp/RtmpWFoxD2/spark_serialize_bdf64b31db10334a157167e3720fb5fda677e92a85e2e167238fb89c721869ff.csv, range: 28130556-33313106, partition values: [empty row]
17/02/16 10:24:45 INFO FileScanRDD: Reading File path: file:///tmp/RtmpWFoxD2/spark_serialize_bdf64b31db10334a157167e3720fb5fda677e92a85e2e167238fb89c721869ff.csv, range: 18753704-28130556, partition values: [empty row]
17/02/16 10:24:46 INFO CodeGenerator: Code generated in 48.576087 ms
17/02/16 10:24:47 INFO ContextCleaner: Cleaned accumulator 397
17/02/16 10:24:47 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:53689 in memory (size: 22.9 KB, free: 366.0 MB)
17/02/16 10:24:47 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:53689 in memory (size: 2.0 KB, free: 366.0 MB)
17/02/16 10:24:47 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:53689 in memory (size: 22.9 KB, free: 366.1 MB)
17/02/16 10:24:47 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:53689 in memory (size: 4.4 KB, free: 366.1 MB)
17/02/16 10:24:47 INFO ContextCleaner: Cleaned accumulator 305
17/02/16 10:24:47 INFO ContextCleaner: Cleaned accumulator 304
17/02/16 10:24:47 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:53689 in memory (size: 22.9 KB, free: 366.1 MB)
17/02/16 10:24:50 INFO MemoryStore: Block rdd_44_3 stored as values in memory (estimated size 3.8 MB, free 361.8 MB)
17/02/16 10:24:50 INFO BlockManagerInfo: Added rdd_44_3 in memory on 127.0.0.1:53689 (size: 3.8 MB, free: 362.3 MB)
17/02/16 10:24:50 INFO Executor: Finished task 3.0 in stage 8.0 (TID 11). 9478 bytes result sent to driver
17/02/16 10:24:50 INFO TaskSetManager: Finished task 3.0 in stage 8.0 (TID 11) in 4112 ms on localhost (1/4)
17/02/16 10:24:51 INFO MemoryStore: Block rdd_44_0 stored as values in memory (estimated size 6.8 MB, free 355.0 MB)
17/02/16 10:24:51 INFO BlockManagerInfo: Added rdd_44_0 in memory on 127.0.0.1:53689 (size: 6.8 MB, free: 355.5 MB)
17/02/16 10:24:51 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 13599 bytes result sent to driver
17/02/16 10:24:51 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 5656 ms on localhost (2/4)
17/02/16 10:24:51 INFO MemoryStore: Block rdd_44_1 stored as values in memory (estimated size 6.9 MB, free 348.1 MB)
17/02/16 10:24:51 INFO BlockManagerInfo: Added rdd_44_1 in memory on 127.0.0.1:53689 (size: 6.9 MB, free: 348.6 MB)
17/02/16 10:24:51 INFO Executor: Finished task 1.0 in stage 8.0 (TID 9). 13634 bytes result sent to driver
17/02/16 10:24:51 INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 9) in 5695 ms on localhost (3/4)
17/02/16 10:24:51 INFO MemoryStore: Block rdd_44_2 stored as values in memory (estimated size 6.9 MB, free 341.2 MB)
17/02/16 10:24:51 INFO BlockManagerInfo: Added rdd_44_2 in memory on 127.0.0.1:53689 (size: 6.9 MB, free: 341.7 MB)
17/02/16 10:24:51 INFO Executor: Finished task 2.0 in stage 8.0 (TID 10). 13624 bytes result sent to driver
17/02/16 10:24:51 INFO TaskSetManager: Finished task 2.0 in stage 8.0 (TID 10) in 5837 ms on localhost (4/4)
17/02/16 10:24:51 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
17/02/16 10:24:51 INFO DAGScheduler: ShuffleMapStage 8 (sql at NativeMethodAccessorImpl.java:-2) finished in 5.840 s
17/02/16 10:24:51 INFO DAGScheduler: looking for newly runnable stages
17/02/16 10:24:51 INFO DAGScheduler: running: Set()
17/02/16 10:24:51 INFO DAGScheduler: waiting: Set(ResultStage 9)
17/02/16 10:24:51 INFO DAGScheduler: failed: Set()
17/02/16 10:24:51 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[50] at sql at NativeMethodAccessorImpl.java:-2), which has no missing parents
17/02/16 10:24:51 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 7.0 KB, free 341.2 MB)
17/02/16 10:24:51 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 3.7 KB, free 341.2 MB)
17/02/16 10:24:51 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:53689 (size: 3.7 KB, free: 341.7 MB)
17/02/16 10:24:51 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1012
17/02/16 10:24:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[50] at sql at NativeMethodAccessorImpl.java:-2)
17/02/16 10:24:51 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
17/02/16 10:24:51 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 12, localhost, partition 0, ANY, 5343 bytes)
17/02/16 10:24:51 INFO Executor: Running task 0.0 in stage 9.0 (TID 12)
17/02/16 10:24:51 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/02/16 10:24:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/02/16 10:24:51 INFO Executor: Finished task 0.0 in stage 9.0 (TID 12). 1873 bytes result sent to driver
17/02/16 10:24:51 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 12) in 8 ms on localhost (1/1)
17/02/16 10:24:51 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
17/02/16 10:24:51 INFO DAGScheduler: ResultStage 9 (sql at NativeMethodAccessorImpl.java:-2) finished in 0.009 s
17/02/16 10:24:51 INFO DAGScheduler: Job 6 finished: sql at NativeMethodAccessorImpl.java:-2, took 5.872269 s
17/02/16 10:24:51 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `flights`
17/02/16 10:24:51 INFO SparkSqlParser: Parsing command: count(1)
17/02/16 10:24:51 INFO SparkContext: Starting job: collect at utils.scala:195
17/02/16 10:24:51 INFO DAGScheduler: Registering RDD 54 (collect at utils.scala:195)
17/02/16 10:24:51 INFO DAGScheduler: Got job 7 (collect at utils.scala:195) with 1 output partitions
17/02/16 10:24:51 INFO DAGScheduler: Final stage: ResultStage 11 (collect at utils.scala:195)
17/02/16 10:24:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
17/02/16 10:24:51 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 10)
17/02/16 10:24:51 INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[54] at collect at utils.scala:195), which has no missing parents
17/02/16 10:24:51 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 24.2 KB, free 341.2 MB)
17/02/16 10:24:51 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 9.9 KB, free 341.2 MB)
17/02/16 10:24:51 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:53689 (size: 9.9 KB, free: 341.7 MB)
17/02/16 10:24:51 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1012
17/02/16 10:24:51 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[54] at collect at utils.scala:195)
17/02/16 10:24:51 INFO TaskSchedulerImpl: Adding task set 10.0 with 4 tasks
17/02/16 10:24:51 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 13, localhost, partition 0, PROCESS_LOCAL, 5982 bytes)
17/02/16 10:24:51 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 14, localhost, partition 1, PROCESS_LOCAL, 5982 bytes)
17/02/16 10:24:51 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 15, localhost, partition 2, PROCESS_LOCAL, 5982 bytes)
17/02/16 10:24:51 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 16, localhost, partition 3, PROCESS_LOCAL, 5982 bytes)
17/02/16 10:24:51 INFO Executor: Running task 0.0 in stage 10.0 (TID 13)
17/02/16 10:24:51 INFO Executor: Running task 3.0 in stage 10.0 (TID 16)
17/02/16 10:24:51 INFO Executor: Running task 1.0 in stage 10.0 (TID 14)
17/02/16 10:24:51 INFO Executor: Running task 2.0 in stage 10.0 (TID 15)
17/02/16 10:24:51 INFO BlockManager: Found block rdd_44_2 locally
17/02/16 10:24:51 INFO BlockManager: Found block rdd_44_3 locally
17/02/16 10:24:51 INFO BlockManager: Found block rdd_44_1 locally
17/02/16 10:24:51 INFO BlockManager: Found block rdd_44_0 locally
17/02/16 10:24:51 INFO Executor: Finished task 1.0 in stage 10.0 (TID 14). 2141 bytes result sent to driver
17/02/16 10:24:51 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 14) in 29 ms on localhost (1/4)
17/02/16 10:24:51 INFO Executor: Finished task 3.0 in stage 10.0 (TID 16). 2141 bytes result sent to driver
17/02/16 10:24:51 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 16) in 36 ms on localhost (2/4)
17/02/16 10:24:51 INFO Executor: Finished task 2.0 in stage 10.0 (TID 15). 2141 bytes result sent to driver
17/02/16 10:24:51 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 15) in 39 ms on localhost (3/4)
17/02/16 10:24:51 INFO Executor: Finished task 0.0 in stage 10.0 (TID 13). 2141 bytes result sent to driver
17/02/16 10:24:51 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 13) in 44 ms on localhost (4/4)
17/02/16 10:24:51 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
17/02/16 10:24:51 INFO DAGScheduler: ShuffleMapStage 10 (collect at utils.scala:195) finished in 0.043 s
17/02/16 10:24:51 INFO DAGScheduler: looking for newly runnable stages
17/02/16 10:24:51 INFO DAGScheduler: running: Set()
17/02/16 10:24:51 INFO DAGScheduler: waiting: Set(ResultStage 11)
17/02/16 10:24:51 INFO DAGScheduler: failed: Set()
17/02/16 10:24:51 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[57] at collect at utils.scala:195), which has no missing parents
17/02/16 10:24:51 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 9.5 KB, free 341.1 MB)
17/02/16 10:24:51 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 4.1 KB, free 341.1 MB)
17/02/16 10:24:51 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:53689 (size: 4.1 KB, free: 341.7 MB)
17/02/16 10:24:51 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1012
17/02/16 10:24:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[57] at collect at utils.scala:195)
17/02/16 10:24:51 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
17/02/16 10:24:51 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 17, localhost, partition 0, ANY, 5336 bytes)
17/02/16 10:24:51 INFO Executor: Running task 0.0 in stage 11.0 (TID 17)
17/02/16 10:24:51 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/02/16 10:24:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/02/16 10:24:51 INFO Executor: Finished task 0.0 in stage 11.0 (TID 17). 2189 bytes result sent to driver
17/02/16 10:24:51 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 17) in 5 ms on localhost (1/1)
17/02/16 10:24:51 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
17/02/16 10:24:51 INFO DAGScheduler: ResultStage 11 (collect at utils.scala:195) finished in 0.005 s
17/02/16 10:24:51 INFO DAGScheduler: Job 7 finished: collect at utils.scala:195, took 0.064489 s
17/02/16 10:24:51 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights` AS `zzz2`
WHERE (0 = 1)
17/02/16 10:24:52 INFO SparkSqlParser: Parsing command: year
17/02/16 10:24:52 INFO SparkSqlParser: Parsing command: month
17/02/16 10:24:52 INFO SparkSqlParser: Parsing command: day
17/02/16 10:24:52 INFO SparkSqlParser: Parsing command: dep_time
17/02/16 10:24:52 INFO SparkSqlParser: Parsing command: sched_dep_time
17/02/16 10:24:52 INFO SparkSqlParser: Parsing command: dep_delay
17/02/16 10:24:52 INFO SparkSqlParser: Parsing command: arr_time
17/02/16 10:24:52 INFO SparkSqlParser: Parsing command: sched_arr_time
17/02/16 10:24:52 INFO SparkSqlParser: Parsing command: arr_delay
17/02/16 10:24:52 INFO SparkSqlParser: Parsing command: carrier
17/02/16 10:24:52 INFO SparkSqlParser: Parsing command: flight
17/02/16 10:24:52 INFO SparkSqlParser: Parsing command: tailnum
17/02/16 10:24:52 INFO SparkSqlParser: Parsing command: origin
17/02/16 10:24:52 INFO SparkSqlParser: Parsing command: dest
17/02/16 10:24:52 INFO SparkSqlParser: Parsing command: air_time
17/02/16 10:24:52 INFO SparkSqlParser: Parsing command: distance
17/02/16 10:24:52 INFO SparkSqlParser: Parsing command: hour
17/02/16 10:24:52 INFO SparkSqlParser: Parsing command: minute
17/02/16 10:24:52 INFO SparkSqlParser: Parsing command: time_hour
17/02/16 10:24:52 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/02/16 10:24:52 INFO HiveMetaStore: 0: get_database: default
17/02/16 10:24:52 INFO audit: ugi=vinayak	ip=unknown-ip-addr	cmd=get_database: default	
17/02/16 10:24:52 INFO HiveMetaStore: 0: get_database: default
17/02/16 10:24:52 INFO audit: ugi=vinayak	ip=unknown-ip-addr	cmd=get_database: default	
17/02/16 10:24:52 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/02/16 10:24:52 INFO audit: ugi=vinayak	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/02/16 10:24:52 INFO SparkContext: Starting job: collect at utils.scala:59
17/02/16 10:24:52 INFO DAGScheduler: Got job 8 (collect at utils.scala:59) with 1 output partitions
17/02/16 10:24:52 INFO DAGScheduler: Final stage: ResultStage 12 (collect at utils.scala:59)
17/02/16 10:24:52 INFO DAGScheduler: Parents of final stage: List()
17/02/16 10:24:52 INFO DAGScheduler: Missing parents: List()
17/02/16 10:24:52 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[63] at map at utils.scala:56), which has no missing parents
17/02/16 10:24:52 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 8.3 KB, free 341.1 MB)
17/02/16 10:24:52 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 4.4 KB, free 341.1 MB)
17/02/16 10:24:52 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:53689 (size: 4.4 KB, free: 341.7 MB)
17/02/16 10:24:52 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1012
17/02/16 10:24:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[63] at map at utils.scala:56)
17/02/16 10:24:52 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
17/02/16 10:24:52 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 18, localhost, partition 0, PROCESS_LOCAL, 5725 bytes)
17/02/16 10:24:52 INFO Executor: Running task 0.0 in stage 12.0 (TID 18)
17/02/16 10:24:52 INFO Executor: Finished task 0.0 in stage 12.0 (TID 18). 1079 bytes result sent to driver
17/02/16 10:24:52 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 18) in 6 ms on localhost (1/1)
17/02/16 10:24:52 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
17/02/16 10:24:52 INFO DAGScheduler: ResultStage 12 (collect at utils.scala:59) finished in 0.007 s
17/02/16 10:24:52 INFO DAGScheduler: Job 8 finished: collect at utils.scala:59, took 0.012307 s
17/02/16 10:24:54 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 209.0 KB, free 340.9 MB)
17/02/16 10:24:55 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 22.9 KB, free 340.9 MB)
17/02/16 10:24:55 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:53689 (size: 22.9 KB, free: 341.7 MB)
17/02/16 10:24:55 INFO SparkContext: Created broadcast 19 from csv at NativeMethodAccessorImpl.java:-2
17/02/16 10:24:55 INFO FileInputFormat: Total input paths to process : 1
17/02/16 10:24:55 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:-2
17/02/16 10:24:55 INFO DAGScheduler: Got job 9 (csv at NativeMethodAccessorImpl.java:-2) with 1 output partitions
17/02/16 10:24:55 INFO DAGScheduler: Final stage: ResultStage 13 (csv at NativeMethodAccessorImpl.java:-2)
17/02/16 10:24:55 INFO DAGScheduler: Parents of final stage: List()
17/02/16 10:24:55 INFO DAGScheduler: Missing parents: List()
17/02/16 10:24:55 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[66] at csv at NativeMethodAccessorImpl.java:-2), which has no missing parents
17/02/16 10:24:55 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 3.4 KB, free 340.9 MB)
17/02/16 10:24:55 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 2.0 KB, free 340.9 MB)
17/02/16 10:24:55 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:53689 (size: 2.0 KB, free: 341.6 MB)
17/02/16 10:24:55 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1012
17/02/16 10:24:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[66] at csv at NativeMethodAccessorImpl.java:-2)
17/02/16 10:24:55 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
17/02/16 10:24:55 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 19, localhost, partition 0, PROCESS_LOCAL, 5503 bytes)
17/02/16 10:24:55 INFO Executor: Running task 0.0 in stage 13.0 (TID 19)
17/02/16 10:24:55 INFO HadoopRDD: Input split: file:/tmp/RtmpWFoxD2/spark_serialize_a7860fa36853b90b80e72911eab9ae08d70b911c204b0a95bf637bdc36920906.csv:0+3377114
17/02/16 10:24:55 INFO Executor: Finished task 0.0 in stage 13.0 (TID 19). 1051 bytes result sent to driver
17/02/16 10:24:55 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 19) in 12 ms on localhost (1/1)
17/02/16 10:24:55 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
17/02/16 10:24:55 INFO DAGScheduler: ResultStage 13 (csv at NativeMethodAccessorImpl.java:-2) finished in 0.013 s
17/02/16 10:24:55 INFO DAGScheduler: Job 9 finished: csv at NativeMethodAccessorImpl.java:-2, took 0.021414 s
17/02/16 10:24:56 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 209.0 KB, free 340.7 MB)
17/02/16 10:24:56 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 22.9 KB, free 340.7 MB)
17/02/16 10:24:56 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:53689 (size: 22.9 KB, free: 341.6 MB)
17/02/16 10:24:56 INFO SparkContext: Created broadcast 21 from csv at NativeMethodAccessorImpl.java:-2
17/02/16 10:24:56 INFO SparkSqlParser: Parsing command: batting
17/02/16 10:24:56 INFO SparkSqlParser: Parsing command: CACHE TABLE `batting`
17/02/16 10:24:56 INFO SparkSqlParser: Parsing command: `batting`
17/02/16 10:24:56 INFO FileSourceStrategy: Pruning directories with: 
17/02/16 10:24:56 INFO FileSourceStrategy: Post-Scan Filters: 
17/02/16 10:24:56 INFO FileSourceStrategy: Pruned Data Schema: struct<playerID: string, yearID: int, stint: int, teamID: string, lgID: string ... 20 more fields>
17/02/16 10:24:56 INFO FileSourceStrategy: Pushed Filters: 
17/02/16 10:24:56 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 242.6 KB, free 340.4 MB)
17/02/16 10:24:56 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 23.4 KB, free 340.4 MB)
17/02/16 10:24:56 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:53689 (size: 23.4 KB, free: 341.6 MB)
17/02/16 10:24:56 INFO SparkContext: Created broadcast 22 from sql at NativeMethodAccessorImpl.java:-2
17/02/16 10:24:56 INFO FileSourceStrategy: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/02/16 10:24:56 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:-2
17/02/16 10:24:56 INFO DAGScheduler: Registering RDD 76 (sql at NativeMethodAccessorImpl.java:-2)
17/02/16 10:24:56 INFO DAGScheduler: Got job 10 (sql at NativeMethodAccessorImpl.java:-2) with 1 output partitions
17/02/16 10:24:56 INFO DAGScheduler: Final stage: ResultStage 15 (sql at NativeMethodAccessorImpl.java:-2)
17/02/16 10:24:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 14)
17/02/16 10:24:56 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 14)
17/02/16 10:24:56 INFO DAGScheduler: Submitting ShuffleMapStage 14 (MapPartitionsRDD[76] at sql at NativeMethodAccessorImpl.java:-2), which has no missing parents
17/02/16 10:24:56 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 26.3 KB, free 340.4 MB)
17/02/16 10:24:56 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 10.4 KB, free 340.4 MB)
17/02/16 10:24:56 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:53689 (size: 10.4 KB, free: 341.6 MB)
17/02/16 10:24:56 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1012
17/02/16 10:24:56 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[76] at sql at NativeMethodAccessorImpl.java:-2)
17/02/16 10:24:56 INFO TaskSchedulerImpl: Adding task set 14.0 with 2 tasks
17/02/16 10:24:56 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 20, localhost, partition 0, PROCESS_LOCAL, 5990 bytes)
17/02/16 10:24:56 INFO TaskSetManager: Starting task 1.0 in stage 14.0 (TID 21, localhost, partition 1, PROCESS_LOCAL, 5990 bytes)
17/02/16 10:24:56 INFO Executor: Running task 0.0 in stage 14.0 (TID 20)
17/02/16 10:24:56 INFO Executor: Running task 1.0 in stage 14.0 (TID 21)
17/02/16 10:24:56 INFO FileScanRDD: Reading File path: file:///tmp/RtmpWFoxD2/spark_serialize_a7860fa36853b90b80e72911eab9ae08d70b911c204b0a95bf637bdc36920906.csv, range: 4194304-6754228, partition values: [empty row]
17/02/16 10:24:56 INFO FileScanRDD: Reading File path: file:///tmp/RtmpWFoxD2/spark_serialize_a7860fa36853b90b80e72911eab9ae08d70b911c204b0a95bf637bdc36920906.csv, range: 0-4194304, partition values: [empty row]
17/02/16 10:24:56 INFO CodeGenerator: Code generated in 25.478735 ms
17/02/16 10:24:57 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:53689 in memory (size: 3.7 KB, free: 341.6 MB)
17/02/16 10:24:57 INFO ContextCleaner: Cleaned accumulator 564
17/02/16 10:24:57 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:53689 in memory (size: 9.9 KB, free: 341.6 MB)
17/02/16 10:24:57 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:53689 in memory (size: 4.1 KB, free: 341.6 MB)
17/02/16 10:24:57 INFO ContextCleaner: Cleaned accumulator 740
17/02/16 10:24:57 INFO ContextCleaner: Cleaned accumulator 741
17/02/16 10:24:57 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:53689 in memory (size: 4.4 KB, free: 341.6 MB)
17/02/16 10:24:57 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:53689 in memory (size: 22.9 KB, free: 341.6 MB)
17/02/16 10:24:57 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:53689 in memory (size: 2.0 KB, free: 341.6 MB)
17/02/16 10:24:57 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 127.0.0.1:53689 in memory (size: 22.9 KB, free: 341.7 MB)
17/02/16 10:24:57 INFO ContextCleaner: Cleaned accumulator 833
17/02/16 10:24:57 INFO MemoryStore: Block rdd_73_1 stored as values in memory (estimated size 1240.3 KB, free 339.7 MB)
17/02/16 10:24:57 INFO BlockManagerInfo: Added rdd_73_1 in memory on 127.0.0.1:53689 (size: 1240.3 KB, free: 340.5 MB)
17/02/16 10:24:57 INFO Executor: Finished task 1.0 in stage 14.0 (TID 21). 7502 bytes result sent to driver
17/02/16 10:24:57 INFO TaskSetManager: Finished task 1.0 in stage 14.0 (TID 21) in 858 ms on localhost (1/2)
17/02/16 10:24:57 INFO MemoryStore: Block rdd_73_0 stored as values in memory (estimated size 2.3 MB, free 337.4 MB)
17/02/16 10:24:57 INFO BlockManagerInfo: Added rdd_73_0 in memory on 127.0.0.1:53689 (size: 2.3 MB, free: 338.2 MB)
17/02/16 10:24:57 INFO Executor: Finished task 0.0 in stage 14.0 (TID 20). 10652 bytes result sent to driver
17/02/16 10:24:57 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 20) in 1049 ms on localhost (2/2)
17/02/16 10:24:57 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
17/02/16 10:24:57 INFO DAGScheduler: ShuffleMapStage 14 (sql at NativeMethodAccessorImpl.java:-2) finished in 1.048 s
17/02/16 10:24:57 INFO DAGScheduler: looking for newly runnable stages
17/02/16 10:24:57 INFO DAGScheduler: running: Set()
17/02/16 10:24:57 INFO DAGScheduler: waiting: Set(ResultStage 15)
17/02/16 10:24:57 INFO DAGScheduler: failed: Set()
17/02/16 10:24:57 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[79] at sql at NativeMethodAccessorImpl.java:-2), which has no missing parents
17/02/16 10:24:57 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 7.0 KB, free 337.4 MB)
17/02/16 10:24:57 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 3.7 KB, free 337.4 MB)
17/02/16 10:24:57 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:53689 (size: 3.7 KB, free: 338.1 MB)
17/02/16 10:24:57 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1012
17/02/16 10:24:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[79] at sql at NativeMethodAccessorImpl.java:-2)
17/02/16 10:24:57 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
17/02/16 10:24:57 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 22, localhost, partition 0, ANY, 5344 bytes)
17/02/16 10:24:57 INFO Executor: Running task 0.0 in stage 15.0 (TID 22)
17/02/16 10:24:57 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/02/16 10:24:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/02/16 10:24:57 INFO Executor: Finished task 0.0 in stage 15.0 (TID 22). 1873 bytes result sent to driver
17/02/16 10:24:57 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 22) in 6 ms on localhost (1/1)
17/02/16 10:24:57 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
17/02/16 10:24:57 INFO DAGScheduler: ResultStage 15 (sql at NativeMethodAccessorImpl.java:-2) finished in 0.007 s
17/02/16 10:24:57 INFO DAGScheduler: Job 10 finished: sql at NativeMethodAccessorImpl.java:-2, took 1.072899 s
17/02/16 10:24:57 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `batting`
17/02/16 10:24:57 INFO SparkSqlParser: Parsing command: count(1)
17/02/16 10:24:57 INFO SparkContext: Starting job: collect at utils.scala:195
17/02/16 10:24:57 INFO DAGScheduler: Registering RDD 83 (collect at utils.scala:195)
17/02/16 10:24:57 INFO DAGScheduler: Got job 11 (collect at utils.scala:195) with 1 output partitions
17/02/16 10:24:57 INFO DAGScheduler: Final stage: ResultStage 17 (collect at utils.scala:195)
17/02/16 10:24:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 16)
17/02/16 10:24:57 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 16)
17/02/16 10:24:57 INFO DAGScheduler: Submitting ShuffleMapStage 16 (MapPartitionsRDD[83] at collect at utils.scala:195), which has no missing parents
17/02/16 10:24:57 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 25.4 KB, free 337.4 MB)
17/02/16 10:24:57 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 10.2 KB, free 337.3 MB)
17/02/16 10:24:57 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 127.0.0.1:53689 (size: 10.2 KB, free: 338.1 MB)
17/02/16 10:24:57 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1012
17/02/16 10:24:57 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[83] at collect at utils.scala:195)
17/02/16 10:24:57 INFO TaskSchedulerImpl: Adding task set 16.0 with 2 tasks
17/02/16 10:24:57 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 23, localhost, partition 0, PROCESS_LOCAL, 5982 bytes)
17/02/16 10:24:57 INFO TaskSetManager: Starting task 1.0 in stage 16.0 (TID 24, localhost, partition 1, PROCESS_LOCAL, 5982 bytes)
17/02/16 10:24:57 INFO Executor: Running task 0.0 in stage 16.0 (TID 23)
17/02/16 10:24:57 INFO Executor: Running task 1.0 in stage 16.0 (TID 24)
17/02/16 10:24:57 INFO BlockManager: Found block rdd_73_0 locally
17/02/16 10:24:57 INFO BlockManager: Found block rdd_73_1 locally
17/02/16 10:24:57 INFO Executor: Finished task 1.0 in stage 16.0 (TID 24). 2141 bytes result sent to driver
17/02/16 10:24:57 INFO Executor: Finished task 0.0 in stage 16.0 (TID 23). 2141 bytes result sent to driver
17/02/16 10:24:57 INFO TaskSetManager: Finished task 1.0 in stage 16.0 (TID 24) in 10 ms on localhost (1/2)
17/02/16 10:24:57 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 23) in 12 ms on localhost (2/2)
17/02/16 10:24:57 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
17/02/16 10:24:57 INFO DAGScheduler: ShuffleMapStage 16 (collect at utils.scala:195) finished in 0.012 s
17/02/16 10:24:57 INFO DAGScheduler: looking for newly runnable stages
17/02/16 10:24:57 INFO DAGScheduler: running: Set()
17/02/16 10:24:57 INFO DAGScheduler: waiting: Set(ResultStage 17)
17/02/16 10:24:57 INFO DAGScheduler: failed: Set()
17/02/16 10:24:57 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[86] at collect at utils.scala:195), which has no missing parents
17/02/16 10:24:57 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 9.5 KB, free 337.3 MB)
17/02/16 10:24:57 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 4.1 KB, free 337.3 MB)
17/02/16 10:24:57 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 127.0.0.1:53689 (size: 4.1 KB, free: 338.1 MB)
17/02/16 10:24:57 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1012
17/02/16 10:24:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[86] at collect at utils.scala:195)
17/02/16 10:24:57 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
17/02/16 10:24:57 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 25, localhost, partition 0, ANY, 5336 bytes)
17/02/16 10:24:57 INFO Executor: Running task 0.0 in stage 17.0 (TID 25)
17/02/16 10:24:57 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/02/16 10:24:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/02/16 10:24:57 INFO Executor: Finished task 0.0 in stage 17.0 (TID 25). 2189 bytes result sent to driver
17/02/16 10:24:57 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 25) in 5 ms on localhost (1/1)
17/02/16 10:24:57 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
17/02/16 10:24:57 INFO DAGScheduler: ResultStage 17 (collect at utils.scala:195) finished in 0.006 s
17/02/16 10:24:57 INFO DAGScheduler: Job 11 finished: collect at utils.scala:195, took 0.034862 s
17/02/16 10:24:57 INFO SparkSqlParser: Parsing command: SELECT *
FROM `batting` AS `zzz3`
WHERE (0 = 1)
17/02/16 10:24:57 INFO SparkSqlParser: Parsing command: playerID
17/02/16 10:24:57 INFO SparkSqlParser: Parsing command: yearID
17/02/16 10:24:57 INFO SparkSqlParser: Parsing command: stint
17/02/16 10:24:57 INFO SparkSqlParser: Parsing command: teamID
17/02/16 10:24:57 INFO SparkSqlParser: Parsing command: lgID
17/02/16 10:24:57 INFO SparkSqlParser: Parsing command: G
17/02/16 10:24:57 INFO SparkSqlParser: Parsing command: AB
17/02/16 10:24:57 INFO SparkSqlParser: Parsing command: R
17/02/16 10:24:57 INFO SparkSqlParser: Parsing command: H
17/02/16 10:24:57 INFO SparkSqlParser: Parsing command: X2B
17/02/16 10:24:57 INFO SparkSqlParser: Parsing command: X3B
17/02/16 10:24:57 INFO SparkSqlParser: Parsing command: HR
17/02/16 10:24:57 INFO SparkSqlParser: Parsing command: RBI
17/02/16 10:24:57 INFO SparkSqlParser: Parsing command: SB
17/02/16 10:24:57 INFO SparkSqlParser: Parsing command: CS
17/02/16 10:24:57 INFO SparkSqlParser: Parsing command: BB
17/02/16 10:24:57 INFO SparkSqlParser: Parsing command: SO
17/02/16 10:24:57 INFO SparkSqlParser: Parsing command: IBB
17/02/16 10:24:57 INFO SparkSqlParser: Parsing command: HBP
17/02/16 10:24:57 INFO SparkSqlParser: Parsing command: SH
17/02/16 10:24:57 INFO SparkSqlParser: Parsing command: SF
17/02/16 10:24:57 INFO SparkSqlParser: Parsing command: GIDP
17/02/16 10:25:11 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights`
17/02/16 10:25:11 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:-2
17/02/16 10:25:11 INFO DAGScheduler: Registering RDD 89 (count at NativeMethodAccessorImpl.java:-2)
17/02/16 10:25:11 INFO DAGScheduler: Got job 12 (count at NativeMethodAccessorImpl.java:-2) with 1 output partitions
17/02/16 10:25:11 INFO DAGScheduler: Final stage: ResultStage 19 (count at NativeMethodAccessorImpl.java:-2)
17/02/16 10:25:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 18)
17/02/16 10:25:11 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 18)
17/02/16 10:25:11 INFO DAGScheduler: Submitting ShuffleMapStage 18 (MapPartitionsRDD[89] at count at NativeMethodAccessorImpl.java:-2), which has no missing parents
17/02/16 10:25:11 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 25.0 KB, free 337.3 MB)
17/02/16 10:25:11 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 10.2 KB, free 337.3 MB)
17/02/16 10:25:11 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 127.0.0.1:53689 (size: 10.2 KB, free: 338.1 MB)
17/02/16 10:25:11 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1012
17/02/16 10:25:11 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[89] at count at NativeMethodAccessorImpl.java:-2)
17/02/16 10:25:11 INFO TaskSchedulerImpl: Adding task set 18.0 with 4 tasks
17/02/16 10:25:11 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 26, localhost, partition 0, PROCESS_LOCAL, 5982 bytes)
17/02/16 10:25:11 INFO TaskSetManager: Starting task 1.0 in stage 18.0 (TID 27, localhost, partition 1, PROCESS_LOCAL, 5982 bytes)
17/02/16 10:25:11 INFO TaskSetManager: Starting task 2.0 in stage 18.0 (TID 28, localhost, partition 2, PROCESS_LOCAL, 5982 bytes)
17/02/16 10:25:11 INFO TaskSetManager: Starting task 3.0 in stage 18.0 (TID 29, localhost, partition 3, PROCESS_LOCAL, 5982 bytes)
17/02/16 10:25:11 INFO Executor: Running task 0.0 in stage 18.0 (TID 26)
17/02/16 10:25:11 INFO Executor: Running task 2.0 in stage 18.0 (TID 28)
17/02/16 10:25:11 INFO Executor: Running task 3.0 in stage 18.0 (TID 29)
17/02/16 10:25:11 INFO Executor: Running task 1.0 in stage 18.0 (TID 27)
17/02/16 10:25:11 INFO BlockManager: Found block rdd_44_0 locally
17/02/16 10:25:11 INFO BlockManager: Found block rdd_44_1 locally
17/02/16 10:25:11 INFO BlockManager: Found block rdd_44_2 locally
17/02/16 10:25:11 INFO BlockManager: Found block rdd_44_3 locally
17/02/16 10:25:11 INFO Executor: Finished task 3.0 in stage 18.0 (TID 29). 2141 bytes result sent to driver
17/02/16 10:25:11 INFO TaskSetManager: Finished task 3.0 in stage 18.0 (TID 29) in 11 ms on localhost (1/4)
17/02/16 10:25:11 INFO Executor: Finished task 2.0 in stage 18.0 (TID 28). 2141 bytes result sent to driver
17/02/16 10:25:11 INFO TaskSetManager: Finished task 2.0 in stage 18.0 (TID 28) in 13 ms on localhost (2/4)
17/02/16 10:25:11 INFO Executor: Finished task 1.0 in stage 18.0 (TID 27). 2141 bytes result sent to driver
17/02/16 10:25:11 INFO TaskSetManager: Finished task 1.0 in stage 18.0 (TID 27) in 26 ms on localhost (3/4)
17/02/16 10:25:11 INFO Executor: Finished task 0.0 in stage 18.0 (TID 26). 2141 bytes result sent to driver
17/02/16 10:25:11 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 26) in 55 ms on localhost (4/4)
17/02/16 10:25:11 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
17/02/16 10:25:11 INFO DAGScheduler: ShuffleMapStage 18 (count at NativeMethodAccessorImpl.java:-2) finished in 0.055 s
17/02/16 10:25:11 INFO DAGScheduler: looking for newly runnable stages
17/02/16 10:25:11 INFO DAGScheduler: running: Set()
17/02/16 10:25:11 INFO DAGScheduler: waiting: Set(ResultStage 19)
17/02/16 10:25:11 INFO DAGScheduler: failed: Set()
17/02/16 10:25:11 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[92] at count at NativeMethodAccessorImpl.java:-2), which has no missing parents
17/02/16 10:25:11 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 7.0 KB, free 337.3 MB)
17/02/16 10:25:11 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 3.7 KB, free 337.3 MB)
17/02/16 10:25:11 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 127.0.0.1:53689 (size: 3.7 KB, free: 338.1 MB)
17/02/16 10:25:11 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1012
17/02/16 10:25:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[92] at count at NativeMethodAccessorImpl.java:-2)
17/02/16 10:25:11 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
17/02/16 10:25:11 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 30, localhost, partition 0, ANY, 5336 bytes)
17/02/16 10:25:11 INFO Executor: Running task 0.0 in stage 19.0 (TID 30)
17/02/16 10:25:11 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/02/16 10:25:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/02/16 10:25:11 INFO Executor: Finished task 0.0 in stage 19.0 (TID 30). 1873 bytes result sent to driver
17/02/16 10:25:11 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 30) in 6 ms on localhost (1/1)
17/02/16 10:25:11 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
17/02/16 10:25:11 INFO DAGScheduler: ResultStage 19 (count at NativeMethodAccessorImpl.java:-2) finished in 0.007 s
17/02/16 10:25:11 INFO DAGScheduler: Job 12 finished: count at NativeMethodAccessorImpl.java:-2, took 0.075639 s
17/02/16 10:25:11 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights`
17/02/16 10:25:11 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:-2
17/02/16 10:25:11 INFO DAGScheduler: Registering RDD 95 (count at NativeMethodAccessorImpl.java:-2)
17/02/16 10:25:11 INFO DAGScheduler: Got job 13 (count at NativeMethodAccessorImpl.java:-2) with 1 output partitions
17/02/16 10:25:11 INFO DAGScheduler: Final stage: ResultStage 21 (count at NativeMethodAccessorImpl.java:-2)
17/02/16 10:25:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 20)
17/02/16 10:25:11 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 20)
17/02/16 10:25:11 INFO DAGScheduler: Submitting ShuffleMapStage 20 (MapPartitionsRDD[95] at count at NativeMethodAccessorImpl.java:-2), which has no missing parents
17/02/16 10:25:11 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 25.0 KB, free 337.3 MB)
17/02/16 10:25:11 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 10.2 KB, free 337.3 MB)
17/02/16 10:25:11 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 127.0.0.1:53689 (size: 10.2 KB, free: 338.1 MB)
17/02/16 10:25:11 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1012
17/02/16 10:25:11 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[95] at count at NativeMethodAccessorImpl.java:-2)
17/02/16 10:25:11 INFO TaskSchedulerImpl: Adding task set 20.0 with 4 tasks
17/02/16 10:25:11 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 31, localhost, partition 0, PROCESS_LOCAL, 5983 bytes)
17/02/16 10:25:11 INFO TaskSetManager: Starting task 1.0 in stage 20.0 (TID 32, localhost, partition 1, PROCESS_LOCAL, 5983 bytes)
17/02/16 10:25:11 INFO TaskSetManager: Starting task 2.0 in stage 20.0 (TID 33, localhost, partition 2, PROCESS_LOCAL, 5983 bytes)
17/02/16 10:25:11 INFO TaskSetManager: Starting task 3.0 in stage 20.0 (TID 34, localhost, partition 3, PROCESS_LOCAL, 5983 bytes)
17/02/16 10:25:11 INFO Executor: Running task 2.0 in stage 20.0 (TID 33)
17/02/16 10:25:11 INFO Executor: Running task 1.0 in stage 20.0 (TID 32)
17/02/16 10:25:11 INFO Executor: Running task 3.0 in stage 20.0 (TID 34)
17/02/16 10:25:11 INFO Executor: Running task 0.0 in stage 20.0 (TID 31)
17/02/16 10:25:11 INFO BlockManager: Found block rdd_44_1 locally
17/02/16 10:25:11 INFO BlockManager: Found block rdd_44_0 locally
17/02/16 10:25:11 INFO BlockManager: Found block rdd_44_2 locally
17/02/16 10:25:11 INFO Executor: Finished task 2.0 in stage 20.0 (TID 33). 2141 bytes result sent to driver
17/02/16 10:25:11 INFO Executor: Finished task 1.0 in stage 20.0 (TID 32). 2141 bytes result sent to driver
17/02/16 10:25:11 INFO TaskSetManager: Finished task 2.0 in stage 20.0 (TID 33) in 10 ms on localhost (1/4)
17/02/16 10:25:11 INFO BlockManager: Found block rdd_44_3 locally
17/02/16 10:25:11 INFO Executor: Finished task 0.0 in stage 20.0 (TID 31). 2141 bytes result sent to driver
17/02/16 10:25:11 INFO TaskSetManager: Finished task 1.0 in stage 20.0 (TID 32) in 11 ms on localhost (2/4)
17/02/16 10:25:11 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 31) in 16 ms on localhost (3/4)
17/02/16 10:25:11 INFO Executor: Finished task 3.0 in stage 20.0 (TID 34). 2141 bytes result sent to driver
17/02/16 10:25:11 INFO TaskSetManager: Finished task 3.0 in stage 20.0 (TID 34) in 18 ms on localhost (4/4)
17/02/16 10:25:11 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
17/02/16 10:25:11 INFO DAGScheduler: ShuffleMapStage 20 (count at NativeMethodAccessorImpl.java:-2) finished in 0.020 s
17/02/16 10:25:11 INFO DAGScheduler: looking for newly runnable stages
17/02/16 10:25:11 INFO DAGScheduler: running: Set()
17/02/16 10:25:11 INFO DAGScheduler: waiting: Set(ResultStage 21)
17/02/16 10:25:11 INFO DAGScheduler: failed: Set()
17/02/16 10:25:11 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[98] at count at NativeMethodAccessorImpl.java:-2), which has no missing parents
17/02/16 10:25:11 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 7.0 KB, free 337.2 MB)
17/02/16 10:25:11 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 3.7 KB, free 337.2 MB)
17/02/16 10:25:11 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 127.0.0.1:53689 (size: 3.7 KB, free: 338.1 MB)
17/02/16 10:25:11 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1012
17/02/16 10:25:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[98] at count at NativeMethodAccessorImpl.java:-2)
17/02/16 10:25:11 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks
17/02/16 10:25:11 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 35, localhost, partition 0, ANY, 5337 bytes)
17/02/16 10:25:11 INFO Executor: Running task 0.0 in stage 21.0 (TID 35)
17/02/16 10:25:11 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/02/16 10:25:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/02/16 10:25:11 INFO Executor: Finished task 0.0 in stage 21.0 (TID 35). 1873 bytes result sent to driver
17/02/16 10:25:11 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 35) in 5 ms on localhost (1/1)
17/02/16 10:25:11 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
17/02/16 10:25:11 INFO DAGScheduler: ResultStage 21 (count at NativeMethodAccessorImpl.java:-2) finished in 0.001 s
17/02/16 10:25:11 INFO DAGScheduler: Job 13 finished: count at NativeMethodAccessorImpl.java:-2, took 0.042076 s
17/02/16 10:25:11 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights`
LIMIT 10
17/02/16 10:25:11 INFO SparkSqlParser: Parsing command: year
17/02/16 10:25:11 INFO SparkSqlParser: Parsing command: month
17/02/16 10:25:11 INFO SparkSqlParser: Parsing command: day
17/02/16 10:25:11 INFO SparkSqlParser: Parsing command: dep_time
17/02/16 10:25:11 INFO SparkSqlParser: Parsing command: sched_dep_time
17/02/16 10:25:11 INFO SparkSqlParser: Parsing command: dep_delay
17/02/16 10:25:11 INFO SparkSqlParser: Parsing command: arr_time
17/02/16 10:25:11 INFO SparkSqlParser: Parsing command: sched_arr_time
17/02/16 10:25:11 INFO SparkSqlParser: Parsing command: arr_delay
17/02/16 10:25:11 INFO SparkSqlParser: Parsing command: carrier
17/02/16 10:25:11 INFO SparkSqlParser: Parsing command: flight
17/02/16 10:25:11 INFO SparkSqlParser: Parsing command: tailnum
17/02/16 10:25:11 INFO SparkSqlParser: Parsing command: origin
17/02/16 10:25:11 INFO SparkSqlParser: Parsing command: dest
17/02/16 10:25:11 INFO SparkSqlParser: Parsing command: air_time
17/02/16 10:25:11 INFO SparkSqlParser: Parsing command: distance
17/02/16 10:25:11 INFO SparkSqlParser: Parsing command: hour
17/02/16 10:25:11 INFO SparkSqlParser: Parsing command: minute
17/02/16 10:25:11 INFO SparkSqlParser: Parsing command: time_hour
17/02/16 10:25:11 INFO SparkContext: Starting job: collect at utils.scala:195
17/02/16 10:25:11 INFO DAGScheduler: Got job 14 (collect at utils.scala:195) with 1 output partitions
17/02/16 10:25:11 INFO DAGScheduler: Final stage: ResultStage 22 (collect at utils.scala:195)
17/02/16 10:25:11 INFO DAGScheduler: Parents of final stage: List()
17/02/16 10:25:11 INFO DAGScheduler: Missing parents: List()
17/02/16 10:25:11 INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[100] at collect at utils.scala:195), which has no missing parents
17/02/16 10:25:11 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 21.2 KB, free 337.2 MB)
17/02/16 10:25:11 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 8.7 KB, free 337.2 MB)
17/02/16 10:25:11 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 127.0.0.1:53689 (size: 8.7 KB, free: 338.1 MB)
17/02/16 10:25:11 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1012
17/02/16 10:25:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[100] at collect at utils.scala:195)
17/02/16 10:25:11 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks
17/02/16 10:25:11 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 36, localhost, partition 0, PROCESS_LOCAL, 5908 bytes)
17/02/16 10:25:11 INFO Executor: Running task 0.0 in stage 22.0 (TID 36)
17/02/16 10:25:11 INFO BlockManager: Found block rdd_44_0 locally
17/02/16 10:25:11 INFO CodeGenerator: Code generated in 101.105518 ms
17/02/16 10:25:11 WARN Executor: 1 block locks were not released by TID = 36:
[rdd_44_0]
17/02/16 10:25:11 INFO Executor: Finished task 0.0 in stage 22.0 (TID 36). 2369 bytes result sent to driver
17/02/16 10:25:11 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 36) in 235 ms on localhost (1/1)
17/02/16 10:25:11 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
17/02/16 10:25:11 INFO DAGScheduler: ResultStage 22 (collect at utils.scala:195) finished in 0.233 s
17/02/16 10:25:11 INFO DAGScheduler: Job 14 finished: collect at utils.scala:195, took 0.243839 s
17/02/16 10:25:11 INFO CodeGenerator: Code generated in 20.824117 ms
17/02/16 10:45:51 INFO SparkContext: Invoking stop() from shutdown hook
17/02/16 10:45:52 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
17/02/16 10:45:52 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/02/16 10:45:53 INFO MemoryStore: MemoryStore cleared
17/02/16 10:45:53 INFO BlockManager: BlockManager stopped
17/02/16 10:45:53 INFO BlockManagerMaster: BlockManagerMaster stopped
17/02/16 10:45:53 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/02/16 10:45:53 INFO SparkContext: Successfully stopped SparkContext
17/02/16 10:45:53 INFO ShutdownHookManager: Shutdown hook called
17/02/16 10:45:53 INFO ShutdownHookManager: Deleting directory /tmp/spark-d50e46bc-9e28-4b0e-b883-3a68be0516e0
17/02/16 14:53:52 INFO SparkContext: Running Spark version 2.0.0
17/02/16 14:53:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/02/16 14:53:53 INFO SecurityManager: Changing view acls to: vinayak
17/02/16 14:53:53 INFO SecurityManager: Changing modify acls to: vinayak
17/02/16 14:53:53 INFO SecurityManager: Changing view acls groups to: 
17/02/16 14:53:53 INFO SecurityManager: Changing modify acls groups to: 
17/02/16 14:53:53 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(vinayak); groups with view permissions: Set(); users  with modify permissions: Set(vinayak); groups with modify permissions: Set()
17/02/16 14:53:54 INFO Utils: Successfully started service 'sparkDriver' on port 35606.
17/02/16 14:53:54 INFO SparkEnv: Registering MapOutputTracker
17/02/16 14:53:54 INFO SparkEnv: Registering BlockManagerMaster
17/02/16 14:53:54 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-2a5bfed6-abf6-45a2-85f4-bc3db36220c5
17/02/16 14:53:54 INFO MemoryStore: MemoryStore started with capacity 366.1 MB
17/02/16 14:53:54 INFO SparkEnv: Registering OutputCommitCoordinator
17/02/16 14:53:55 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/02/16 14:53:55 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
17/02/16 14:53:55 INFO SparkContext: Added JAR file:/home/vinayak/R/i686-pc-linux-gnu-library/3.3/sparklyr/java/sparklyr-2.0-2.11.jar at spark://127.0.0.1:35606/jars/sparklyr-2.0-2.11.jar with timestamp 1487237035129
17/02/16 14:53:55 INFO Executor: Starting executor ID driver on host localhost
17/02/16 14:53:55 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 47988.
17/02/16 14:53:55 INFO NettyBlockTransferService: Server created on 127.0.0.1:47988
17/02/16 14:53:55 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 47988)
17/02/16 14:53:55 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:47988 with 366.1 MB RAM, BlockManagerId(driver, 127.0.0.1, 47988)
17/02/16 14:53:55 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 47988)
17/02/16 14:53:55 WARN SparkContext: Use an existing SparkContext, some configuration may not take effect.
17/02/16 14:53:56 WARN SparkContext: Use an existing SparkContext, some configuration may not take effect.
17/02/16 14:53:56 INFO HiveSharedState: Warehouse path is 'file:/home/vinayak/sudhakar/R/automation_model/spark-warehouse'.
17/02/16 14:53:56 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/02/16 14:53:59 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
17/02/16 14:54:00 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
17/02/16 14:54:00 INFO ObjectStore: ObjectStore, initialize called
17/02/16 14:54:00 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
17/02/16 14:54:00 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
17/02/16 14:54:03 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
17/02/16 14:54:04 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/02/16 14:54:04 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/02/16 14:54:05 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/02/16 14:54:05 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/02/16 14:54:05 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
17/02/16 14:54:05 INFO ObjectStore: Initialized ObjectStore
17/02/16 14:54:06 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
17/02/16 14:54:06 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
17/02/16 14:54:06 INFO HiveMetaStore: Added admin role in metastore
17/02/16 14:54:06 INFO HiveMetaStore: Added public role in metastore
17/02/16 14:54:06 INFO HiveMetaStore: No user is added in admin role, since config is empty
17/02/16 14:54:06 INFO HiveMetaStore: 0: get_all_databases
17/02/16 14:54:06 INFO audit: ugi=vinayak	ip=unknown-ip-addr	cmd=get_all_databases	
17/02/16 14:54:07 INFO HiveMetaStore: 0: get_functions: db=default pat=*
17/02/16 14:54:07 INFO audit: ugi=vinayak	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
17/02/16 14:54:07 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
17/02/16 14:54:07 INFO SessionState: Created local directory: /tmp/2b776249-9952-462d-83ab-11ef898a7869_resources
17/02/16 14:54:07 INFO SessionState: Created HDFS directory: /tmp/hive/vinayak/2b776249-9952-462d-83ab-11ef898a7869
17/02/16 14:54:07 INFO SessionState: Created local directory: /tmp/vinayak/2b776249-9952-462d-83ab-11ef898a7869
17/02/16 14:54:07 INFO SessionState: Created HDFS directory: /tmp/hive/vinayak/2b776249-9952-462d-83ab-11ef898a7869/_tmp_space.db
17/02/16 14:54:07 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/home/vinayak/sudhakar/R/automation_model/spark-warehouse
17/02/16 14:54:07 INFO SessionState: Created local directory: /tmp/c0f37356-2483-4f75-8bdc-bd3fcf8aa4eb_resources
17/02/16 14:54:07 INFO SessionState: Created HDFS directory: /tmp/hive/vinayak/c0f37356-2483-4f75-8bdc-bd3fcf8aa4eb
17/02/16 14:54:07 INFO SessionState: Created local directory: /tmp/vinayak/c0f37356-2483-4f75-8bdc-bd3fcf8aa4eb
17/02/16 14:54:07 INFO SessionState: Created HDFS directory: /tmp/hive/vinayak/c0f37356-2483-4f75-8bdc-bd3fcf8aa4eb/_tmp_space.db
17/02/16 14:54:07 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/home/vinayak/sudhakar/R/automation_model/spark-warehouse
17/02/16 14:54:08 INFO HiveMetaStore: 0: create_database: Database(name:default, description:default database, locationUri:file:/home/vinayak/sudhakar/R/automation_model/spark-warehouse, parameters:{})
17/02/16 14:54:08 INFO audit: ugi=vinayak	ip=unknown-ip-addr	cmd=create_database: Database(name:default, description:default database, locationUri:file:/home/vinayak/sudhakar/R/automation_model/spark-warehouse, parameters:{})	
17/02/16 14:54:09 INFO HiveMetaStore: 0: get_database: default
17/02/16 14:54:09 INFO audit: ugi=vinayak	ip=unknown-ip-addr	cmd=get_database: default	
17/02/16 14:54:09 INFO HiveMetaStore: 0: get_database: default
17/02/16 14:54:09 INFO audit: ugi=vinayak	ip=unknown-ip-addr	cmd=get_database: default	
17/02/16 14:54:09 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/02/16 14:54:09 INFO audit: ugi=vinayak	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/02/16 14:54:09 INFO SparkSqlParser: Parsing command: tableName
17/02/16 14:54:09 INFO SparkSqlParser: Parsing command: isTemporary
17/02/16 14:54:10 INFO SparkContext: Starting job: collect at utils.scala:195
17/02/16 14:54:10 INFO DAGScheduler: Got job 0 (collect at utils.scala:195) with 1 output partitions
17/02/16 14:54:10 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:195)
17/02/16 14:54:10 INFO DAGScheduler: Parents of final stage: List()
17/02/16 14:54:10 INFO DAGScheduler: Missing parents: List()
17/02/16 14:54:10 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[2] at collect at utils.scala:195), which has no missing parents
17/02/16 14:54:10 WARN SizeEstimator: Failed to check whether UseCompressedOops is set; assuming yes
17/02/16 14:54:10 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 4.0 KB, free 366.1 MB)
17/02/16 14:54:10 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 2.4 KB, free 366.1 MB)
17/02/16 14:54:10 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:47988 (size: 2.4 KB, free: 366.1 MB)
17/02/16 14:54:10 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1012
17/02/16 14:54:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at collect at utils.scala:195)
17/02/16 14:54:10 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
17/02/16 14:54:10 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5443 bytes)
17/02/16 14:54:10 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/02/16 14:54:10 INFO Executor: Fetching spark://127.0.0.1:35606/jars/sparklyr-2.0-2.11.jar with timestamp 1487237035129
17/02/16 14:54:10 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:35606 after 13 ms (0 ms spent in bootstraps)
17/02/16 14:54:10 INFO Utils: Fetching spark://127.0.0.1:35606/jars/sparklyr-2.0-2.11.jar to /tmp/spark-64cd0ee2-dcc1-428b-961d-adb1b0acff0b/userFiles-c69e15e8-fc06-4f17-b003-a6911e938d7d/fetchFileTemp5501148498313396899.tmp
17/02/16 14:54:10 INFO Executor: Adding file:/tmp/spark-64cd0ee2-dcc1-428b-961d-adb1b0acff0b/userFiles-c69e15e8-fc06-4f17-b003-a6911e938d7d/sparklyr-2.0-2.11.jar to class loader
17/02/16 14:54:11 INFO CodeGenerator: Code generated in 462.484416 ms
17/02/16 14:54:11 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1021 bytes result sent to driver
17/02/16 14:54:11 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1035 ms on localhost (1/1)
17/02/16 14:54:11 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/02/16 14:54:11 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:195) finished in 1.089 s
17/02/16 14:54:11 INFO DAGScheduler: Job 0 finished: collect at utils.scala:195, took 1.465694 s
17/02/16 15:23:56 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:47988 in memory (size: 2.4 KB, free: 366.1 MB)
17/02/16 16:22:36 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/02/16 16:22:36 INFO HiveMetaStore: 0: get_database: default
17/02/16 16:22:36 INFO audit: ugi=vinayak	ip=unknown-ip-addr	cmd=get_database: default	
17/02/16 16:22:36 INFO HiveMetaStore: 0: get_database: default
17/02/16 16:22:36 INFO audit: ugi=vinayak	ip=unknown-ip-addr	cmd=get_database: default	
17/02/16 16:22:36 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/02/16 16:22:36 INFO audit: ugi=vinayak	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/02/16 16:22:36 INFO CodeGenerator: Code generated in 161.351982 ms
17/02/16 16:22:37 INFO SparkContext: Starting job: collect at utils.scala:59
17/02/16 16:22:37 INFO DAGScheduler: Got job 1 (collect at utils.scala:59) with 1 output partitions
17/02/16 16:22:37 INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:59)
17/02/16 16:22:37 INFO DAGScheduler: Parents of final stage: List()
17/02/16 16:22:37 INFO DAGScheduler: Missing parents: List()
17/02/16 16:22:37 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[8] at map at utils.scala:56), which has no missing parents
17/02/16 16:22:37 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 8.3 KB, free 366.1 MB)
17/02/16 16:22:37 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.4 KB, free 366.1 MB)
17/02/16 16:22:37 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:47988 (size: 4.4 KB, free: 366.1 MB)
17/02/16 16:22:37 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1012
17/02/16 16:22:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at map at utils.scala:56)
17/02/16 16:22:37 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
17/02/16 16:22:37 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5415 bytes)
17/02/16 16:22:37 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
17/02/16 16:22:37 INFO CodeGenerator: Code generated in 17.246541 ms
17/02/16 16:22:37 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1062 bytes result sent to driver
17/02/16 16:22:37 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 183 ms on localhost (1/1)
17/02/16 16:22:37 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/02/16 16:22:37 INFO DAGScheduler: ResultStage 1 (collect at utils.scala:59) finished in 0.183 s
17/02/16 16:22:37 INFO DAGScheduler: Job 1 finished: collect at utils.scala:59, took 0.296594 s
17/02/16 16:22:38 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 64.6 KB, free 366.1 MB)
17/02/16 16:22:38 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 22.9 KB, free 366.1 MB)
17/02/16 16:22:38 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:47988 (size: 22.9 KB, free: 366.1 MB)
17/02/16 16:22:38 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:-2
17/02/16 16:22:38 INFO FileInputFormat: Total input paths to process : 1
17/02/16 16:22:38 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:-2
17/02/16 16:22:38 INFO DAGScheduler: Got job 2 (csv at NativeMethodAccessorImpl.java:-2) with 1 output partitions
17/02/16 16:22:38 INFO DAGScheduler: Final stage: ResultStage 2 (csv at NativeMethodAccessorImpl.java:-2)
17/02/16 16:22:38 INFO DAGScheduler: Parents of final stage: List()
17/02/16 16:22:38 INFO DAGScheduler: Missing parents: List()
17/02/16 16:22:38 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[11] at csv at NativeMethodAccessorImpl.java:-2), which has no missing parents
17/02/16 16:22:38 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 3.3 KB, free 366.0 MB)
17/02/16 16:22:38 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 2027.0 B, free 366.0 MB)
17/02/16 16:22:38 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:47988 (size: 2027.0 B, free: 366.1 MB)
17/02/16 16:22:38 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1012
17/02/16 16:22:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[11] at csv at NativeMethodAccessorImpl.java:-2)
17/02/16 16:22:38 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
17/02/16 16:22:38 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5452 bytes)
17/02/16 16:22:38 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
17/02/16 16:22:38 INFO HadoopRDD: Input split: file:/home/vinayak/Desktop/toKaran/Churn_prediction.csv:0+1463648
17/02/16 16:22:38 INFO deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
17/02/16 16:22:38 INFO deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
17/02/16 16:22:38 INFO deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
17/02/16 16:22:38 INFO deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
17/02/16 16:22:38 INFO deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
17/02/16 16:22:38 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1313 bytes result sent to driver
17/02/16 16:22:38 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 355 ms on localhost (1/1)
17/02/16 16:22:38 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/02/16 16:22:38 INFO DAGScheduler: ResultStage 2 (csv at NativeMethodAccessorImpl.java:-2) finished in 0.356 s
17/02/16 16:22:38 INFO DAGScheduler: Job 2 finished: csv at NativeMethodAccessorImpl.java:-2, took 0.380710 s
17/02/16 16:22:39 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 209.0 KB, free 365.8 MB)
17/02/16 16:22:39 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 22.9 KB, free 365.8 MB)
17/02/16 16:22:39 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:47988 (size: 22.9 KB, free: 366.1 MB)
17/02/16 16:22:39 INFO SparkContext: Created broadcast 4 from csv at NativeMethodAccessorImpl.java:-2
17/02/16 16:22:39 INFO FileInputFormat: Total input paths to process : 1
17/02/16 16:22:39 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:-2
17/02/16 16:22:39 INFO DAGScheduler: Got job 3 (csv at NativeMethodAccessorImpl.java:-2) with 1 output partitions
17/02/16 16:22:39 INFO DAGScheduler: Final stage: ResultStage 3 (csv at NativeMethodAccessorImpl.java:-2)
17/02/16 16:22:39 INFO DAGScheduler: Parents of final stage: List()
17/02/16 16:22:39 INFO DAGScheduler: Missing parents: List()
17/02/16 16:22:39 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[14] at csv at NativeMethodAccessorImpl.java:-2), which has no missing parents
17/02/16 16:22:39 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 3.3 KB, free 365.8 MB)
17/02/16 16:22:39 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 2029.0 B, free 365.8 MB)
17/02/16 16:22:39 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:47988 (size: 2029.0 B, free: 366.1 MB)
17/02/16 16:22:39 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1012
17/02/16 16:22:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[14] at csv at NativeMethodAccessorImpl.java:-2)
17/02/16 16:22:39 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
17/02/16 16:22:39 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 5452 bytes)
17/02/16 16:22:39 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
17/02/16 16:22:39 INFO HadoopRDD: Input split: file:/home/vinayak/Desktop/toKaran/Churn_prediction.csv:0+1463648
17/02/16 16:22:39 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1226 bytes result sent to driver
17/02/16 16:22:39 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 10 ms on localhost (1/1)
17/02/16 16:22:39 INFO DAGScheduler: ResultStage 3 (csv at NativeMethodAccessorImpl.java:-2) finished in 0.010 s
17/02/16 16:22:39 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/02/16 16:22:39 INFO DAGScheduler: Job 3 finished: csv at NativeMethodAccessorImpl.java:-2, took 0.018439 s
17/02/16 16:22:39 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:-2
17/02/16 16:22:39 INFO DAGScheduler: Got job 4 (csv at NativeMethodAccessorImpl.java:-2) with 2 output partitions
17/02/16 16:22:39 INFO DAGScheduler: Final stage: ResultStage 4 (csv at NativeMethodAccessorImpl.java:-2)
17/02/16 16:22:39 INFO DAGScheduler: Parents of final stage: List()
17/02/16 16:22:39 INFO DAGScheduler: Missing parents: List()
17/02/16 16:22:39 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[15] at csv at NativeMethodAccessorImpl.java:-2), which has no missing parents
17/02/16 16:22:39 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 5.5 KB, free 365.8 MB)
17/02/16 16:22:39 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.2 KB, free 365.8 MB)
17/02/16 16:22:39 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:47988 (size: 3.2 KB, free: 366.1 MB)
17/02/16 16:22:39 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1012
17/02/16 16:22:39 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[15] at csv at NativeMethodAccessorImpl.java:-2)
17/02/16 16:22:39 INFO TaskSchedulerImpl: Adding task set 4.0 with 2 tasks
17/02/16 16:22:39 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5456 bytes)
17/02/16 16:22:39 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 5, localhost, partition 1, PROCESS_LOCAL, 5456 bytes)
17/02/16 16:22:39 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
17/02/16 16:22:39 INFO Executor: Running task 1.0 in stage 4.0 (TID 5)
17/02/16 16:22:39 INFO HadoopRDD: Input split: file:/home/vinayak/Desktop/toKaran/Churn_prediction.csv:0+1463648
17/02/16 16:22:39 INFO HadoopRDD: Input split: file:/home/vinayak/Desktop/toKaran/Churn_prediction.csv:1463648+1463648
17/02/16 16:22:39 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:47988 in memory (size: 2029.0 B, free: 366.1 MB)
17/02/16 16:22:39 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:47988 in memory (size: 2027.0 B, free: 366.1 MB)
17/02/16 16:22:39 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:47988 in memory (size: 4.4 KB, free: 366.1 MB)
17/02/16 16:22:39 INFO Executor: Finished task 1.0 in stage 4.0 (TID 5). 1329 bytes result sent to driver
17/02/16 16:22:39 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 5) in 589 ms on localhost (1/2)
17/02/16 16:22:39 INFO ContextCleaner: Cleaned accumulator 46
17/02/16 16:22:39 INFO ContextCleaner: Cleaned accumulator 45
17/02/16 16:22:39 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1242 bytes result sent to driver
17/02/16 16:22:39 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 598 ms on localhost (2/2)
17/02/16 16:22:39 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
17/02/16 16:22:39 INFO DAGScheduler: ResultStage 4 (csv at NativeMethodAccessorImpl.java:-2) finished in 0.599 s
17/02/16 16:22:39 INFO DAGScheduler: Job 4 finished: csv at NativeMethodAccessorImpl.java:-2, took 0.606761 s
17/02/16 16:22:39 INFO SparkSqlParser: Parsing command: Churn
17/02/16 16:22:39 INFO SparkSqlParser: Parsing command: CACHE TABLE `Churn`
17/02/16 16:22:39 INFO SparkSqlParser: Parsing command: `Churn`
17/02/16 16:22:40 INFO FileSourceStrategy: Pruning directories with: 
17/02/16 16:22:40 INFO FileSourceStrategy: Post-Scan Filters: 
17/02/16 16:22:40 INFO FileSourceStrategy: Pruned Data Schema: struct<ID: int, CreditLimit: int, Sex: int, Education: int, MaritalStatus: int ... 24 more fields>
17/02/16 16:22:40 INFO FileSourceStrategy: Pushed Filters: 
17/02/16 16:22:40 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 243.4 KB, free 365.6 MB)
17/02/16 16:22:40 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 23.6 KB, free 365.6 MB)
17/02/16 16:22:40 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:47988 (size: 23.6 KB, free: 366.1 MB)
17/02/16 16:22:40 INFO SparkContext: Created broadcast 7 from sql at NativeMethodAccessorImpl.java:-2
17/02/16 16:22:40 INFO FileSourceStrategy: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/02/16 16:22:40 WARN Utils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf.
17/02/16 16:22:40 INFO CodeGenerator: Code generated in 9.562826 ms
17/02/16 16:22:40 INFO CodeGenerator: Code generated in 62.23716 ms
17/02/16 16:22:41 INFO CodeGenerator: Code generated in 14.889721 ms
17/02/16 16:22:41 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:-2
17/02/16 16:22:41 INFO DAGScheduler: Registering RDD 22 (sql at NativeMethodAccessorImpl.java:-2)
17/02/16 16:22:41 INFO DAGScheduler: Got job 5 (sql at NativeMethodAccessorImpl.java:-2) with 1 output partitions
17/02/16 16:22:41 INFO DAGScheduler: Final stage: ResultStage 6 (sql at NativeMethodAccessorImpl.java:-2)
17/02/16 16:22:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
17/02/16 16:22:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
17/02/16 16:22:41 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[22] at sql at NativeMethodAccessorImpl.java:-2), which has no missing parents
17/02/16 16:22:41 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 29.8 KB, free 365.5 MB)
17/02/16 16:22:41 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 11.4 KB, free 365.5 MB)
17/02/16 16:22:41 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:47988 (size: 11.4 KB, free: 366.1 MB)
17/02/16 16:22:41 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1012
17/02/16 16:22:41 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[22] at sql at NativeMethodAccessorImpl.java:-2)
17/02/16 16:22:41 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
17/02/16 16:22:41 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 6, localhost, partition 0, PROCESS_LOCAL, 5939 bytes)
17/02/16 16:22:41 INFO Executor: Running task 0.0 in stage 5.0 (TID 6)
17/02/16 16:22:41 INFO FileScanRDD: Reading File path: file:///home/vinayak/Desktop/toKaran/Churn_prediction.csv, range: 0-2927296, partition values: [empty row]
17/02/16 16:22:41 INFO CodeGenerator: Code generated in 37.139616 ms
17/02/16 16:22:42 INFO ContextCleaner: Cleaned accumulator 248
17/02/16 16:22:42 INFO MemoryStore: Block rdd_19_0 stored as values in memory (estimated size 1815.8 KB, free 363.8 MB)
17/02/16 16:22:42 INFO BlockManagerInfo: Added rdd_19_0 in memory on 127.0.0.1:47988 (size: 1815.8 KB, free: 364.3 MB)
17/02/16 16:22:42 INFO CodeGenerator: Code generated in 8.428366 ms
17/02/16 16:22:42 INFO CodeGenerator: Code generated in 35.593878 ms
17/02/16 16:22:42 INFO Executor: Finished task 0.0 in stage 5.0 (TID 6). 6806 bytes result sent to driver
17/02/16 16:22:42 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 6) in 1449 ms on localhost (1/1)
17/02/16 16:22:42 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/02/16 16:22:42 INFO DAGScheduler: ShuffleMapStage 5 (sql at NativeMethodAccessorImpl.java:-2) finished in 1.451 s
17/02/16 16:22:42 INFO DAGScheduler: looking for newly runnable stages
17/02/16 16:22:42 INFO DAGScheduler: running: Set()
17/02/16 16:22:42 INFO DAGScheduler: waiting: Set(ResultStage 6)
17/02/16 16:22:42 INFO DAGScheduler: failed: Set()
17/02/16 16:22:42 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[25] at sql at NativeMethodAccessorImpl.java:-2), which has no missing parents
17/02/16 16:22:42 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 7.0 KB, free 363.7 MB)
17/02/16 16:22:42 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.7 KB, free 363.7 MB)
17/02/16 16:22:42 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:47988 (size: 3.7 KB, free: 364.3 MB)
17/02/16 16:22:42 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1012
17/02/16 16:22:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[25] at sql at NativeMethodAccessorImpl.java:-2)
17/02/16 16:22:42 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
17/02/16 16:22:42 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 7, localhost, partition 0, ANY, 5343 bytes)
17/02/16 16:22:42 INFO Executor: Running task 0.0 in stage 6.0 (TID 7)
17/02/16 16:22:42 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/02/16 16:22:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 13 ms
17/02/16 16:22:42 INFO Executor: Finished task 0.0 in stage 6.0 (TID 7). 1960 bytes result sent to driver
17/02/16 16:22:42 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 7) in 97 ms on localhost (1/1)
17/02/16 16:22:42 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
17/02/16 16:22:42 INFO DAGScheduler: ResultStage 6 (sql at NativeMethodAccessorImpl.java:-2) finished in 0.097 s
17/02/16 16:22:42 INFO DAGScheduler: Job 5 finished: sql at NativeMethodAccessorImpl.java:-2, took 1.717544 s
17/02/16 16:22:42 INFO CodeGenerator: Code generated in 9.441753 ms
17/02/16 16:22:42 INFO SparkContext: Starting job: collect at utils.scala:195
17/02/16 16:22:42 INFO DAGScheduler: Got job 6 (collect at utils.scala:195) with 1 output partitions
17/02/16 16:22:42 INFO DAGScheduler: Final stage: ResultStage 7 (collect at utils.scala:195)
17/02/16 16:22:42 INFO DAGScheduler: Parents of final stage: List()
17/02/16 16:22:42 INFO DAGScheduler: Missing parents: List()
17/02/16 16:22:42 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[28] at collect at utils.scala:195), which has no missing parents
17/02/16 16:22:42 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 3.2 KB, free 363.7 MB)
17/02/16 16:22:42 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 1981.0 B, free 363.7 MB)
17/02/16 16:22:42 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:47988 (size: 1981.0 B, free: 364.3 MB)
17/02/16 16:22:42 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1012
17/02/16 16:22:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[28] at collect at utils.scala:195)
17/02/16 16:22:42 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
17/02/16 16:22:42 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 8, localhost, partition 0, PROCESS_LOCAL, 5444 bytes)
17/02/16 16:22:42 INFO Executor: Running task 0.0 in stage 7.0 (TID 8)
17/02/16 16:22:42 INFO CodeGenerator: Code generated in 7.910406 ms
17/02/16 16:22:42 INFO Executor: Finished task 0.0 in stage 7.0 (TID 8). 1021 bytes result sent to driver
17/02/16 16:22:42 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 8) in 17 ms on localhost (1/1)
17/02/16 16:22:42 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
17/02/16 16:22:42 INFO DAGScheduler: ResultStage 7 (collect at utils.scala:195) finished in 0.014 s
17/02/16 16:22:42 INFO DAGScheduler: Job 6 finished: collect at utils.scala:195, took 0.024925 s
17/02/16 16:22:42 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `Churn`
17/02/16 16:22:43 INFO SparkSqlParser: Parsing command: count(1)
17/02/16 16:22:43 INFO CodeGenerator: Code generated in 19.727862 ms
17/02/16 16:22:43 INFO CodeGenerator: Code generated in 9.665441 ms
17/02/16 16:22:43 INFO SparkContext: Starting job: collect at utils.scala:195
17/02/16 16:22:43 INFO DAGScheduler: Registering RDD 31 (collect at utils.scala:195)
17/02/16 16:22:43 INFO DAGScheduler: Got job 7 (collect at utils.scala:195) with 1 output partitions
17/02/16 16:22:43 INFO DAGScheduler: Final stage: ResultStage 9 (collect at utils.scala:195)
17/02/16 16:22:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
17/02/16 16:22:43 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 8)
17/02/16 16:22:43 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[31] at collect at utils.scala:195), which has no missing parents
17/02/16 16:22:43 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 29.0 KB, free 363.7 MB)
17/02/16 16:22:43 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 11.0 KB, free 363.7 MB)
17/02/16 16:22:43 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:47988 (size: 11.0 KB, free: 364.3 MB)
17/02/16 16:22:43 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1012
17/02/16 16:22:43 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[31] at collect at utils.scala:195)
17/02/16 16:22:43 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
17/02/16 16:22:43 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 9, localhost, partition 0, PROCESS_LOCAL, 5931 bytes)
17/02/16 16:22:43 INFO Executor: Running task 0.0 in stage 8.0 (TID 9)
17/02/16 16:22:43 INFO BlockManager: Found block rdd_19_0 locally
17/02/16 16:22:43 INFO Executor: Finished task 0.0 in stage 8.0 (TID 9). 2141 bytes result sent to driver
17/02/16 16:22:43 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 9) in 25 ms on localhost (1/1)
17/02/16 16:22:43 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
17/02/16 16:22:43 INFO DAGScheduler: ShuffleMapStage 8 (collect at utils.scala:195) finished in 0.026 s
17/02/16 16:22:43 INFO DAGScheduler: looking for newly runnable stages
17/02/16 16:22:43 INFO DAGScheduler: running: Set()
17/02/16 16:22:43 INFO DAGScheduler: waiting: Set(ResultStage 9)
17/02/16 16:22:43 INFO DAGScheduler: failed: Set()
17/02/16 16:22:43 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[34] at collect at utils.scala:195), which has no missing parents
17/02/16 16:22:43 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 9.5 KB, free 363.7 MB)
17/02/16 16:22:43 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 4.1 KB, free 363.7 MB)
17/02/16 16:22:43 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:47988 (size: 4.1 KB, free: 364.3 MB)
17/02/16 16:22:43 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1012
17/02/16 16:22:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[34] at collect at utils.scala:195)
17/02/16 16:22:43 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
17/02/16 16:22:43 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 10, localhost, partition 0, ANY, 5335 bytes)
17/02/16 16:22:43 INFO Executor: Running task 0.0 in stage 9.0 (TID 10)
17/02/16 16:22:43 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/02/16 16:22:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/02/16 16:22:43 INFO Executor: Finished task 0.0 in stage 9.0 (TID 10). 2189 bytes result sent to driver
17/02/16 16:22:43 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 10) in 12 ms on localhost (1/1)
17/02/16 16:22:43 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
17/02/16 16:22:43 INFO DAGScheduler: ResultStage 9 (collect at utils.scala:195) finished in 0.013 s
17/02/16 16:22:43 INFO DAGScheduler: Job 7 finished: collect at utils.scala:195, took 0.067655 s
17/02/16 16:22:43 INFO SparkSqlParser: Parsing command: SELECT *
FROM `Churn` AS `zzz1`
WHERE (0 = 1)
17/02/16 16:22:43 INFO SparkSqlParser: Parsing command: ID
17/02/16 16:22:43 INFO SparkSqlParser: Parsing command: CreditLimit
17/02/16 16:22:43 INFO SparkSqlParser: Parsing command: Sex
17/02/16 16:22:43 INFO SparkSqlParser: Parsing command: Education
17/02/16 16:22:43 INFO SparkSqlParser: Parsing command: MaritalStatus
17/02/16 16:22:43 INFO SparkSqlParser: Parsing command: Age
17/02/16 16:22:43 INFO SparkSqlParser: Parsing command: RPStatusSep
17/02/16 16:22:43 INFO SparkSqlParser: Parsing command: RPStatusAug
17/02/16 16:22:43 INFO SparkSqlParser: Parsing command: RPStatusJuly
17/02/16 16:22:43 INFO SparkSqlParser: Parsing command: RPStatusJune
17/02/16 16:22:43 INFO SparkSqlParser: Parsing command: RPStatusMay
17/02/16 16:22:43 INFO SparkSqlParser: Parsing command: RPStatusApril
17/02/16 16:22:43 INFO SparkSqlParser: Parsing command: BILL_AMT_Sept
17/02/16 16:22:43 INFO SparkSqlParser: Parsing command: BILL_AMT_August
17/02/16 16:22:43 INFO SparkSqlParser: Parsing command: BILL_AMT_July
17/02/16 16:22:43 INFO SparkSqlParser: Parsing command: BILL_AMT_June
17/02/16 16:22:43 INFO SparkSqlParser: Parsing command: BILL_AMT_May
17/02/16 16:22:43 INFO SparkSqlParser: Parsing command: BILL_AMT_April
17/02/16 16:22:43 INFO SparkSqlParser: Parsing command: PAY_AMT_Sept
17/02/16 16:22:43 INFO SparkSqlParser: Parsing command: PAY_AMT_August
17/02/16 16:22:43 INFO SparkSqlParser: Parsing command: PAY_AMT_July
17/02/16 16:22:43 INFO SparkSqlParser: Parsing command: PAY_AMT_June
17/02/16 16:22:43 INFO SparkSqlParser: Parsing command: PAY_AMT_May
17/02/16 16:22:43 INFO SparkSqlParser: Parsing command: PAY_AMT_April
17/02/16 16:22:43 INFO SparkSqlParser: Parsing command: default
17/02/16 16:22:43 INFO SparkSqlParser: Parsing command: message
17/02/16 16:22:43 INFO SparkSqlParser: Parsing command: SELECT *
FROM `Churn`
17/02/16 16:22:43 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:-2
17/02/16 16:22:43 INFO DAGScheduler: Registering RDD 37 (count at NativeMethodAccessorImpl.java:-2)
17/02/16 16:22:43 INFO DAGScheduler: Got job 8 (count at NativeMethodAccessorImpl.java:-2) with 1 output partitions
17/02/16 16:22:43 INFO DAGScheduler: Final stage: ResultStage 11 (count at NativeMethodAccessorImpl.java:-2)
17/02/16 16:22:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
17/02/16 16:22:43 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 10)
17/02/16 16:22:43 INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[37] at count at NativeMethodAccessorImpl.java:-2), which has no missing parents
17/02/16 16:22:43 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 29.8 KB, free 363.7 MB)
17/02/16 16:22:43 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 11.3 KB, free 363.6 MB)
17/02/16 16:22:43 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:47988 (size: 11.3 KB, free: 364.3 MB)
17/02/16 16:22:43 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1012
17/02/16 16:22:43 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[37] at count at NativeMethodAccessorImpl.java:-2)
17/02/16 16:22:43 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
17/02/16 16:22:43 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 11, localhost, partition 0, PROCESS_LOCAL, 5931 bytes)
17/02/16 16:22:43 INFO Executor: Running task 0.0 in stage 10.0 (TID 11)
17/02/16 16:22:43 INFO BlockManager: Found block rdd_19_0 locally
17/02/16 16:22:43 INFO Executor: Finished task 0.0 in stage 10.0 (TID 11). 2141 bytes result sent to driver
17/02/16 16:22:43 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 11) in 18 ms on localhost (1/1)
17/02/16 16:22:43 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
17/02/16 16:22:43 INFO DAGScheduler: ShuffleMapStage 10 (count at NativeMethodAccessorImpl.java:-2) finished in 0.018 s
17/02/16 16:22:43 INFO DAGScheduler: looking for newly runnable stages
17/02/16 16:22:43 INFO DAGScheduler: running: Set()
17/02/16 16:22:43 INFO DAGScheduler: waiting: Set(ResultStage 11)
17/02/16 16:22:43 INFO DAGScheduler: failed: Set()
17/02/16 16:22:43 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[40] at count at NativeMethodAccessorImpl.java:-2), which has no missing parents
17/02/16 16:22:43 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 7.0 KB, free 363.6 MB)
17/02/16 16:22:43 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 3.7 KB, free 363.6 MB)
17/02/16 16:22:43 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:47988 (size: 3.7 KB, free: 364.3 MB)
17/02/16 16:22:43 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1012
17/02/16 16:22:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[40] at count at NativeMethodAccessorImpl.java:-2)
17/02/16 16:22:43 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
17/02/16 16:22:43 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 12, localhost, partition 0, ANY, 5335 bytes)
17/02/16 16:22:43 INFO Executor: Running task 0.0 in stage 11.0 (TID 12)
17/02/16 16:22:43 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/02/16 16:22:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/02/16 16:22:43 INFO Executor: Finished task 0.0 in stage 11.0 (TID 12). 1873 bytes result sent to driver
17/02/16 16:22:43 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 12) in 9 ms on localhost (1/1)
17/02/16 16:22:43 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
17/02/16 16:22:43 INFO DAGScheduler: ResultStage 11 (count at NativeMethodAccessorImpl.java:-2) finished in 0.010 s
17/02/16 16:22:43 INFO DAGScheduler: Job 8 finished: count at NativeMethodAccessorImpl.java:-2, took 0.083555 s
17/02/16 16:22:43 INFO SparkSqlParser: Parsing command: SELECT *
FROM `Churn`
17/02/16 16:22:43 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:-2
17/02/16 16:22:43 INFO DAGScheduler: Registering RDD 43 (count at NativeMethodAccessorImpl.java:-2)
17/02/16 16:22:43 INFO DAGScheduler: Got job 9 (count at NativeMethodAccessorImpl.java:-2) with 1 output partitions
17/02/16 16:22:43 INFO DAGScheduler: Final stage: ResultStage 13 (count at NativeMethodAccessorImpl.java:-2)
17/02/16 16:22:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)
17/02/16 16:22:43 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 12)
17/02/16 16:22:43 INFO DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[43] at count at NativeMethodAccessorImpl.java:-2), which has no missing parents
17/02/16 16:22:43 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 29.8 KB, free 363.6 MB)
17/02/16 16:22:43 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 11.4 KB, free 363.6 MB)
17/02/16 16:22:43 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:47988 (size: 11.4 KB, free: 364.2 MB)
17/02/16 16:22:43 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1012
17/02/16 16:22:43 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[43] at count at NativeMethodAccessorImpl.java:-2)
17/02/16 16:22:43 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
17/02/16 16:22:43 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 13, localhost, partition 0, PROCESS_LOCAL, 5932 bytes)
17/02/16 16:22:43 INFO Executor: Running task 0.0 in stage 12.0 (TID 13)
17/02/16 16:22:43 INFO BlockManager: Found block rdd_19_0 locally
17/02/16 16:22:43 INFO Executor: Finished task 0.0 in stage 12.0 (TID 13). 2141 bytes result sent to driver
17/02/16 16:22:43 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 13) in 11 ms on localhost (1/1)
17/02/16 16:22:43 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
17/02/16 16:22:43 INFO DAGScheduler: ShuffleMapStage 12 (count at NativeMethodAccessorImpl.java:-2) finished in 0.011 s
17/02/16 16:22:43 INFO DAGScheduler: looking for newly runnable stages
17/02/16 16:22:43 INFO DAGScheduler: running: Set()
17/02/16 16:22:43 INFO DAGScheduler: waiting: Set(ResultStage 13)
17/02/16 16:22:43 INFO DAGScheduler: failed: Set()
17/02/16 16:22:43 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[46] at count at NativeMethodAccessorImpl.java:-2), which has no missing parents
17/02/16 16:22:43 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 7.0 KB, free 363.6 MB)
17/02/16 16:22:43 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 3.7 KB, free 363.6 MB)
17/02/16 16:22:43 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:47988 (size: 3.7 KB, free: 364.2 MB)
17/02/16 16:22:43 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1012
17/02/16 16:22:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[46] at count at NativeMethodAccessorImpl.java:-2)
17/02/16 16:22:43 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
17/02/16 16:22:43 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 14, localhost, partition 0, ANY, 5336 bytes)
17/02/16 16:22:43 INFO Executor: Running task 0.0 in stage 13.0 (TID 14)
17/02/16 16:22:43 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/02/16 16:22:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/02/16 16:22:43 INFO Executor: Finished task 0.0 in stage 13.0 (TID 14). 1873 bytes result sent to driver
17/02/16 16:22:44 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 14) in 5 ms on localhost (1/1)
17/02/16 16:22:44 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
17/02/16 16:22:44 INFO DAGScheduler: ResultStage 13 (count at NativeMethodAccessorImpl.java:-2) finished in 0.006 s
17/02/16 16:22:44 INFO DAGScheduler: Job 9 finished: count at NativeMethodAccessorImpl.java:-2, took 0.033592 s
17/02/16 16:22:44 INFO SparkSqlParser: Parsing command: SELECT *
FROM `Churn`
LIMIT 10
17/02/16 16:22:44 INFO SparkSqlParser: Parsing command: ID
17/02/16 16:22:44 INFO SparkSqlParser: Parsing command: CreditLimit
17/02/16 16:22:44 INFO SparkSqlParser: Parsing command: Sex
17/02/16 16:22:44 INFO SparkSqlParser: Parsing command: Education
17/02/16 16:22:44 INFO SparkSqlParser: Parsing command: MaritalStatus
17/02/16 16:22:44 INFO SparkSqlParser: Parsing command: Age
17/02/16 16:22:44 INFO SparkSqlParser: Parsing command: RPStatusSep
17/02/16 16:22:44 INFO SparkSqlParser: Parsing command: RPStatusAug
17/02/16 16:22:44 INFO SparkSqlParser: Parsing command: RPStatusJuly
17/02/16 16:22:44 INFO SparkSqlParser: Parsing command: RPStatusJune
17/02/16 16:22:44 INFO SparkSqlParser: Parsing command: RPStatusMay
17/02/16 16:22:44 INFO SparkSqlParser: Parsing command: RPStatusApril
17/02/16 16:22:44 INFO SparkSqlParser: Parsing command: BILL_AMT_Sept
17/02/16 16:22:44 INFO SparkSqlParser: Parsing command: BILL_AMT_August
17/02/16 16:22:44 INFO SparkSqlParser: Parsing command: BILL_AMT_July
17/02/16 16:22:44 INFO SparkSqlParser: Parsing command: BILL_AMT_June
17/02/16 16:22:44 INFO SparkSqlParser: Parsing command: BILL_AMT_May
17/02/16 16:22:44 INFO SparkSqlParser: Parsing command: BILL_AMT_April
17/02/16 16:22:44 INFO SparkSqlParser: Parsing command: PAY_AMT_Sept
17/02/16 16:22:44 INFO SparkSqlParser: Parsing command: PAY_AMT_August
17/02/16 16:22:44 INFO SparkSqlParser: Parsing command: PAY_AMT_July
17/02/16 16:22:44 INFO SparkSqlParser: Parsing command: PAY_AMT_June
17/02/16 16:22:44 INFO SparkSqlParser: Parsing command: PAY_AMT_May
17/02/16 16:22:44 INFO SparkSqlParser: Parsing command: PAY_AMT_April
17/02/16 16:22:44 INFO SparkSqlParser: Parsing command: default
17/02/16 16:22:44 INFO SparkSqlParser: Parsing command: message
17/02/16 16:22:44 INFO SparkContext: Starting job: collect at utils.scala:195
17/02/16 16:22:44 INFO DAGScheduler: Got job 10 (collect at utils.scala:195) with 1 output partitions
17/02/16 16:22:44 INFO DAGScheduler: Final stage: ResultStage 14 (collect at utils.scala:195)
17/02/16 16:22:44 INFO DAGScheduler: Parents of final stage: List()
17/02/16 16:22:44 INFO DAGScheduler: Missing parents: List()
17/02/16 16:22:44 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[48] at collect at utils.scala:195), which has no missing parents
17/02/16 16:22:44 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 26.0 KB, free 363.6 MB)
17/02/16 16:22:44 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 10.0 KB, free 363.6 MB)
17/02/16 16:22:44 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:47988 (size: 10.0 KB, free: 364.2 MB)
17/02/16 16:22:44 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1012
17/02/16 16:22:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[48] at collect at utils.scala:195)
17/02/16 16:22:44 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
17/02/16 16:22:44 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 15, localhost, partition 0, PROCESS_LOCAL, 5857 bytes)
17/02/16 16:22:44 INFO Executor: Running task 0.0 in stage 14.0 (TID 15)
17/02/16 16:22:44 INFO BlockManager: Found block rdd_19_0 locally
17/02/16 16:22:44 INFO CodeGenerator: Code generated in 58.795872 ms
17/02/16 16:22:44 WARN Executor: 1 block locks were not released by TID = 15:
[rdd_19_0]
17/02/16 16:22:44 INFO Executor: Finished task 0.0 in stage 14.0 (TID 15). 2409 bytes result sent to driver
17/02/16 16:22:44 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 15) in 297 ms on localhost (1/1)
17/02/16 16:22:44 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
17/02/16 16:22:44 INFO DAGScheduler: ResultStage 14 (collect at utils.scala:195) finished in 0.298 s
17/02/16 16:22:44 INFO DAGScheduler: Job 10 finished: collect at utils.scala:195, took 0.306877 s
17/02/16 16:22:44 INFO CodeGenerator: Code generated in 23.190555 ms
17/02/16 16:22:44 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/02/16 16:22:44 INFO HiveMetaStore: 0: get_database: default
17/02/16 16:22:44 INFO audit: ugi=vinayak	ip=unknown-ip-addr	cmd=get_database: default	
17/02/16 16:22:44 INFO HiveMetaStore: 0: get_database: default
17/02/16 16:22:44 INFO audit: ugi=vinayak	ip=unknown-ip-addr	cmd=get_database: default	
17/02/16 16:22:44 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/02/16 16:22:44 INFO audit: ugi=vinayak	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/02/16 16:22:44 INFO SparkSqlParser: Parsing command: tableName
17/02/16 16:22:44 INFO SparkSqlParser: Parsing command: isTemporary
17/02/16 16:22:44 INFO SparkContext: Starting job: collect at utils.scala:195
17/02/16 16:22:44 INFO DAGScheduler: Got job 11 (collect at utils.scala:195) with 1 output partitions
17/02/16 16:22:44 INFO DAGScheduler: Final stage: ResultStage 15 (collect at utils.scala:195)
17/02/16 16:22:44 INFO DAGScheduler: Parents of final stage: List()
17/02/16 16:22:44 INFO DAGScheduler: Missing parents: List()
17/02/16 16:22:44 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[51] at collect at utils.scala:195), which has no missing parents
17/02/16 16:22:44 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 4.0 KB, free 363.5 MB)
17/02/16 16:22:44 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 2.5 KB, free 363.5 MB)
17/02/16 16:22:44 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:47988 (size: 2.5 KB, free: 364.2 MB)
17/02/16 16:22:44 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1012
17/02/16 16:22:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[51] at collect at utils.scala:195)
17/02/16 16:22:44 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
17/02/16 16:22:44 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 16, localhost, partition 0, PROCESS_LOCAL, 5714 bytes)
17/02/16 16:22:44 INFO Executor: Running task 0.0 in stage 15.0 (TID 16)
17/02/16 16:22:44 INFO Executor: Finished task 0.0 in stage 15.0 (TID 16). 1137 bytes result sent to driver
17/02/16 16:22:44 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 16) in 7 ms on localhost (1/1)
17/02/16 16:22:44 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
17/02/16 16:22:44 INFO DAGScheduler: ResultStage 15 (collect at utils.scala:195) finished in 0.008 s
17/02/16 16:22:44 INFO DAGScheduler: Job 11 finished: collect at utils.scala:195, took 0.015644 s
17/02/16 16:22:44 INFO CodeGenerator: Code generated in 8.715908 ms
17/02/16 16:22:57 INFO SparkSqlParser: Parsing command: SELECT * FROM churn LIMIT 5
17/02/16 16:22:57 INFO SparkSqlParser: Parsing command: ID
17/02/16 16:22:57 INFO SparkSqlParser: Parsing command: CreditLimit
17/02/16 16:22:57 INFO SparkSqlParser: Parsing command: Sex
17/02/16 16:22:57 INFO SparkSqlParser: Parsing command: Education
17/02/16 16:22:57 INFO SparkSqlParser: Parsing command: MaritalStatus
17/02/16 16:22:57 INFO SparkSqlParser: Parsing command: Age
17/02/16 16:22:57 INFO SparkSqlParser: Parsing command: RPStatusSep
17/02/16 16:22:57 INFO SparkSqlParser: Parsing command: RPStatusAug
17/02/16 16:22:57 INFO SparkSqlParser: Parsing command: RPStatusJuly
17/02/16 16:22:57 INFO SparkSqlParser: Parsing command: RPStatusJune
17/02/16 16:22:57 INFO SparkSqlParser: Parsing command: RPStatusMay
17/02/16 16:22:57 INFO SparkSqlParser: Parsing command: RPStatusApril
17/02/16 16:22:57 INFO SparkSqlParser: Parsing command: BILL_AMT_Sept
17/02/16 16:22:57 INFO SparkSqlParser: Parsing command: BILL_AMT_August
17/02/16 16:22:57 INFO SparkSqlParser: Parsing command: BILL_AMT_July
17/02/16 16:22:57 INFO SparkSqlParser: Parsing command: BILL_AMT_June
17/02/16 16:22:57 INFO SparkSqlParser: Parsing command: BILL_AMT_May
17/02/16 16:22:57 INFO SparkSqlParser: Parsing command: BILL_AMT_April
17/02/16 16:22:57 INFO SparkSqlParser: Parsing command: PAY_AMT_Sept
17/02/16 16:22:57 INFO SparkSqlParser: Parsing command: PAY_AMT_August
17/02/16 16:22:57 INFO SparkSqlParser: Parsing command: PAY_AMT_July
17/02/16 16:22:57 INFO SparkSqlParser: Parsing command: PAY_AMT_June
17/02/16 16:22:57 INFO SparkSqlParser: Parsing command: PAY_AMT_May
17/02/16 16:22:57 INFO SparkSqlParser: Parsing command: PAY_AMT_April
17/02/16 16:22:57 INFO SparkSqlParser: Parsing command: default
17/02/16 16:22:57 INFO SparkSqlParser: Parsing command: message
17/02/16 16:22:57 INFO SparkContext: Starting job: collect at utils.scala:195
17/02/16 16:22:57 INFO DAGScheduler: Got job 12 (collect at utils.scala:195) with 1 output partitions
17/02/16 16:22:57 INFO DAGScheduler: Final stage: ResultStage 16 (collect at utils.scala:195)
17/02/16 16:22:57 INFO DAGScheduler: Parents of final stage: List()
17/02/16 16:22:57 INFO DAGScheduler: Missing parents: List()
17/02/16 16:22:57 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[53] at collect at utils.scala:195), which has no missing parents
17/02/16 16:22:57 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 26.0 KB, free 363.5 MB)
17/02/16 16:22:57 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 9.9 KB, free 363.5 MB)
17/02/16 16:22:57 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:47988 (size: 9.9 KB, free: 364.2 MB)
17/02/16 16:22:57 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1012
17/02/16 16:22:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[53] at collect at utils.scala:195)
17/02/16 16:22:57 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
17/02/16 16:22:57 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 17, localhost, partition 0, PROCESS_LOCAL, 5857 bytes)
17/02/16 16:22:57 INFO Executor: Running task 0.0 in stage 16.0 (TID 17)
17/02/16 16:22:57 INFO BlockManager: Found block rdd_19_0 locally
17/02/16 16:22:57 WARN Executor: 1 block locks were not released by TID = 17:
[rdd_19_0]
17/02/16 16:22:57 INFO Executor: Finished task 0.0 in stage 16.0 (TID 17). 1963 bytes result sent to driver
17/02/16 16:22:57 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 17) in 11 ms on localhost (1/1)
17/02/16 16:22:57 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
17/02/16 16:22:57 INFO DAGScheduler: ResultStage 16 (collect at utils.scala:195) finished in 0.011 s
17/02/16 16:22:57 INFO DAGScheduler: Job 12 finished: collect at utils.scala:195, took 0.021328 s
17/02/16 16:23:03 INFO SparkSqlParser: Parsing command: SELECT * FROM churn LIMIT 1000
17/02/16 16:23:03 INFO SparkSqlParser: Parsing command: ID
17/02/16 16:23:03 INFO SparkSqlParser: Parsing command: CreditLimit
17/02/16 16:23:03 INFO SparkSqlParser: Parsing command: Sex
17/02/16 16:23:03 INFO SparkSqlParser: Parsing command: Education
17/02/16 16:23:03 INFO SparkSqlParser: Parsing command: MaritalStatus
17/02/16 16:23:03 INFO SparkSqlParser: Parsing command: Age
17/02/16 16:23:03 INFO SparkSqlParser: Parsing command: RPStatusSep
17/02/16 16:23:03 INFO SparkSqlParser: Parsing command: RPStatusAug
17/02/16 16:23:03 INFO SparkSqlParser: Parsing command: RPStatusJuly
17/02/16 16:23:03 INFO SparkSqlParser: Parsing command: RPStatusJune
17/02/16 16:23:03 INFO SparkSqlParser: Parsing command: RPStatusMay
17/02/16 16:23:03 INFO SparkSqlParser: Parsing command: RPStatusApril
17/02/16 16:23:03 INFO SparkSqlParser: Parsing command: BILL_AMT_Sept
17/02/16 16:23:03 INFO SparkSqlParser: Parsing command: BILL_AMT_August
17/02/16 16:23:03 INFO SparkSqlParser: Parsing command: BILL_AMT_July
17/02/16 16:23:03 INFO SparkSqlParser: Parsing command: BILL_AMT_June
17/02/16 16:23:03 INFO SparkSqlParser: Parsing command: BILL_AMT_May
17/02/16 16:23:03 INFO SparkSqlParser: Parsing command: BILL_AMT_April
17/02/16 16:23:03 INFO SparkSqlParser: Parsing command: PAY_AMT_Sept
17/02/16 16:23:03 INFO SparkSqlParser: Parsing command: PAY_AMT_August
17/02/16 16:23:03 INFO SparkSqlParser: Parsing command: PAY_AMT_July
17/02/16 16:23:03 INFO SparkSqlParser: Parsing command: PAY_AMT_June
17/02/16 16:23:03 INFO SparkSqlParser: Parsing command: PAY_AMT_May
17/02/16 16:23:03 INFO SparkSqlParser: Parsing command: PAY_AMT_April
17/02/16 16:23:03 INFO SparkSqlParser: Parsing command: default
17/02/16 16:23:03 INFO SparkSqlParser: Parsing command: message
17/02/16 16:23:03 INFO SparkContext: Starting job: collect at utils.scala:195
17/02/16 16:23:03 INFO DAGScheduler: Got job 13 (collect at utils.scala:195) with 1 output partitions
17/02/16 16:23:03 INFO DAGScheduler: Final stage: ResultStage 17 (collect at utils.scala:195)
17/02/16 16:23:03 INFO DAGScheduler: Parents of final stage: List()
17/02/16 16:23:03 INFO DAGScheduler: Missing parents: List()
17/02/16 16:23:03 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[55] at collect at utils.scala:195), which has no missing parents
17/02/16 16:23:03 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 26.0 KB, free 363.5 MB)
17/02/16 16:23:03 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 9.9 KB, free 363.5 MB)
17/02/16 16:23:03 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:47988 (size: 9.9 KB, free: 364.2 MB)
17/02/16 16:23:03 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1012
17/02/16 16:23:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[55] at collect at utils.scala:195)
17/02/16 16:23:03 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
17/02/16 16:23:03 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 18, localhost, partition 0, PROCESS_LOCAL, 5858 bytes)
17/02/16 16:23:03 INFO Executor: Running task 0.0 in stage 17.0 (TID 18)
17/02/16 16:23:03 INFO BlockManager: Found block rdd_19_0 locally
17/02/16 16:23:03 WARN Executor: 1 block locks were not released by TID = 18:
[rdd_19_0]
17/02/16 16:23:03 INFO Executor: Finished task 0.0 in stage 17.0 (TID 18). 78389 bytes result sent to driver
17/02/16 16:23:03 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 18) in 41 ms on localhost (1/1)
17/02/16 16:23:03 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
17/02/16 16:23:03 INFO DAGScheduler: ResultStage 17 (collect at utils.scala:195) finished in 0.041 s
17/02/16 16:23:03 INFO DAGScheduler: Job 13 finished: collect at utils.scala:195, took 0.050067 s
17/02/16 16:23:56 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:47988 in memory (size: 11.4 KB, free: 364.2 MB)
17/02/16 16:23:56 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:47988 in memory (size: 9.9 KB, free: 364.2 MB)
17/02/16 16:23:56 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:47988 in memory (size: 3.7 KB, free: 364.2 MB)
17/02/16 16:23:56 INFO ContextCleaner: Cleaned accumulator 605
17/02/16 16:23:56 INFO ContextCleaner: Cleaned accumulator 606
17/02/16 16:23:56 INFO ContextCleaner: Cleaned accumulator 607
17/02/16 16:23:56 INFO ContextCleaner: Cleaned accumulator 608
17/02/16 16:23:56 INFO ContextCleaner: Cleaned accumulator 609
17/02/16 16:23:56 INFO ContextCleaner: Cleaned accumulator 610
17/02/16 16:23:56 INFO ContextCleaner: Cleaned accumulator 611
17/02/16 16:23:56 INFO ContextCleaner: Cleaned accumulator 612
17/02/16 16:23:56 INFO ContextCleaner: Cleaned accumulator 613
17/02/16 16:23:56 INFO ContextCleaner: Cleaned accumulator 614
17/02/16 16:23:56 INFO ContextCleaner: Cleaned accumulator 615
17/02/16 16:23:56 INFO ContextCleaner: Cleaned accumulator 616
17/02/16 16:23:56 INFO ContextCleaner: Cleaned accumulator 617
17/02/16 16:23:56 INFO ContextCleaner: Cleaned shuffle 3
17/02/16 16:23:56 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:47988 in memory (size: 11.4 KB, free: 364.2 MB)
17/02/16 16:23:56 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:47988 in memory (size: 3.7 KB, free: 364.3 MB)
17/02/16 16:23:56 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:47988 in memory (size: 10.0 KB, free: 364.3 MB)
17/02/16 16:23:56 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:47988 in memory (size: 2.5 KB, free: 364.3 MB)
17/02/16 16:23:56 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:47988 in memory (size: 9.9 KB, free: 364.3 MB)
17/02/16 16:23:56 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:47988 in memory (size: 3.7 KB, free: 364.3 MB)
17/02/16 16:23:56 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:47988 in memory (size: 1981.0 B, free: 364.3 MB)
17/02/16 16:23:56 INFO ContextCleaner: Cleaned accumulator 394
17/02/16 16:23:56 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:47988 in memory (size: 11.0 KB, free: 364.3 MB)
17/02/16 16:23:56 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:47988 in memory (size: 4.1 KB, free: 364.3 MB)
17/02/16 16:23:56 INFO ContextCleaner: Cleaned accumulator 504
17/02/16 16:23:56 INFO ContextCleaner: Cleaned accumulator 505
17/02/16 16:23:56 INFO ContextCleaner: Cleaned accumulator 506
17/02/16 16:23:56 INFO ContextCleaner: Cleaned accumulator 507
17/02/16 16:23:56 INFO ContextCleaner: Cleaned accumulator 508
17/02/16 16:23:56 INFO ContextCleaner: Cleaned accumulator 509
17/02/16 16:23:56 INFO ContextCleaner: Cleaned accumulator 510
17/02/16 16:23:56 INFO ContextCleaner: Cleaned accumulator 511
17/02/16 16:23:56 INFO ContextCleaner: Cleaned accumulator 512
17/02/16 16:23:56 INFO ContextCleaner: Cleaned accumulator 513
17/02/16 16:23:56 INFO ContextCleaner: Cleaned accumulator 514
17/02/16 16:23:56 INFO ContextCleaner: Cleaned accumulator 515
17/02/16 16:23:56 INFO ContextCleaner: Cleaned accumulator 516
17/02/16 16:23:56 INFO ContextCleaner: Cleaned shuffle 2
17/02/16 16:23:56 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:47988 in memory (size: 11.3 KB, free: 364.3 MB)
17/02/16 16:23:56 INFO ContextCleaner: Cleaned shuffle 0
17/02/16 16:23:56 INFO ContextCleaner: Cleaned accumulator 260
17/02/16 16:23:56 INFO ContextCleaner: Cleaned accumulator 259
17/02/16 16:23:56 INFO ContextCleaner: Cleaned accumulator 258
17/02/16 16:23:56 INFO ContextCleaner: Cleaned accumulator 257
17/02/16 16:23:56 INFO ContextCleaner: Cleaned accumulator 256
17/02/16 16:23:56 INFO ContextCleaner: Cleaned accumulator 255
17/02/16 16:23:56 INFO ContextCleaner: Cleaned accumulator 254
17/02/16 16:23:56 INFO ContextCleaner: Cleaned accumulator 253
17/02/16 16:23:56 INFO ContextCleaner: Cleaned accumulator 252
17/02/16 16:23:56 INFO ContextCleaner: Cleaned accumulator 251
17/02/16 16:23:56 INFO ContextCleaner: Cleaned accumulator 250
17/02/16 16:23:56 INFO ContextCleaner: Cleaned accumulator 249
17/02/16 16:23:56 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:47988 in memory (size: 3.2 KB, free: 364.3 MB)
17/02/16 16:23:56 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:47988 in memory (size: 22.9 KB, free: 364.3 MB)
17/02/16 16:23:56 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:47988 in memory (size: 22.9 KB, free: 364.4 MB)
17/02/16 16:24:07 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/02/16 16:24:07 INFO HiveMetaStore: 0: get_database: default
17/02/16 16:24:07 INFO audit: ugi=vinayak	ip=unknown-ip-addr	cmd=get_database: default	
17/02/16 16:24:07 INFO HiveMetaStore: 0: get_database: default
17/02/16 16:24:07 INFO audit: ugi=vinayak	ip=unknown-ip-addr	cmd=get_database: default	
17/02/16 16:24:07 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/02/16 16:24:07 INFO audit: ugi=vinayak	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/02/16 16:24:07 INFO SparkContext: Starting job: collect at utils.scala:59
17/02/16 16:24:07 INFO DAGScheduler: Got job 14 (collect at utils.scala:59) with 1 output partitions
17/02/16 16:24:07 INFO DAGScheduler: Final stage: ResultStage 18 (collect at utils.scala:59)
17/02/16 16:24:07 INFO DAGScheduler: Parents of final stage: List()
17/02/16 16:24:07 INFO DAGScheduler: Missing parents: List()
17/02/16 16:24:07 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[61] at map at utils.scala:56), which has no missing parents
17/02/16 16:24:07 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 8.3 KB, free 364.1 MB)
17/02/16 16:24:07 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 4.4 KB, free 364.1 MB)
17/02/16 16:24:07 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:47988 (size: 4.4 KB, free: 364.3 MB)
17/02/16 16:24:07 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1012
17/02/16 16:24:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[61] at map at utils.scala:56)
17/02/16 16:24:07 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks
17/02/16 16:24:07 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 19, localhost, partition 0, PROCESS_LOCAL, 5685 bytes)
17/02/16 16:24:07 INFO Executor: Running task 0.0 in stage 18.0 (TID 19)
17/02/16 16:24:07 INFO Executor: Finished task 0.0 in stage 18.0 (TID 19). 1070 bytes result sent to driver
17/02/16 16:24:07 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 19) in 12 ms on localhost (1/1)
17/02/16 16:24:07 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
17/02/16 16:24:07 INFO DAGScheduler: ResultStage 18 (collect at utils.scala:59) finished in 0.013 s
17/02/16 16:24:07 INFO DAGScheduler: Job 14 finished: collect at utils.scala:59, took 0.020155 s
17/02/16 16:24:07 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 209.0 KB, free 363.9 MB)
17/02/16 16:24:07 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 22.9 KB, free 363.9 MB)
17/02/16 16:24:07 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:47988 (size: 22.9 KB, free: 364.3 MB)
17/02/16 16:24:07 INFO SparkContext: Created broadcast 22 from csv at NativeMethodAccessorImpl.java:-2
17/02/16 16:24:07 INFO FileInputFormat: Total input paths to process : 1
17/02/16 16:24:07 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:-2
17/02/16 16:24:07 INFO DAGScheduler: Got job 15 (csv at NativeMethodAccessorImpl.java:-2) with 1 output partitions
17/02/16 16:24:07 INFO DAGScheduler: Final stage: ResultStage 19 (csv at NativeMethodAccessorImpl.java:-2)
17/02/16 16:24:07 INFO DAGScheduler: Parents of final stage: List()
17/02/16 16:24:07 INFO DAGScheduler: Missing parents: List()
17/02/16 16:24:07 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[64] at csv at NativeMethodAccessorImpl.java:-2), which has no missing parents
17/02/16 16:24:07 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 3.3 KB, free 363.9 MB)
17/02/16 16:24:07 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 2029.0 B, free 363.9 MB)
17/02/16 16:24:07 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:47988 (size: 2029.0 B, free: 364.3 MB)
17/02/16 16:24:07 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1012
17/02/16 16:24:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[64] at csv at NativeMethodAccessorImpl.java:-2)
17/02/16 16:24:07 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
17/02/16 16:24:07 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 20, localhost, partition 0, PROCESS_LOCAL, 5453 bytes)
17/02/16 16:24:07 INFO Executor: Running task 0.0 in stage 19.0 (TID 20)
17/02/16 16:24:07 INFO HadoopRDD: Input split: file:/home/vinayak/Desktop/toKaran/Churn_prediction.csv:0+1463648
17/02/16 16:24:07 INFO Executor: Finished task 0.0 in stage 19.0 (TID 20). 1226 bytes result sent to driver
17/02/16 16:24:07 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 20) in 11 ms on localhost (1/1)
17/02/16 16:24:07 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
17/02/16 16:24:07 INFO DAGScheduler: ResultStage 19 (csv at NativeMethodAccessorImpl.java:-2) finished in 0.011 s
17/02/16 16:24:07 INFO DAGScheduler: Job 15 finished: csv at NativeMethodAccessorImpl.java:-2, took 0.018148 s
17/02/16 16:24:07 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 209.0 KB, free 363.7 MB)
17/02/16 16:24:08 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 22.9 KB, free 363.6 MB)
17/02/16 16:24:08 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:47988 (size: 22.9 KB, free: 364.3 MB)
17/02/16 16:24:08 INFO SparkContext: Created broadcast 24 from csv at NativeMethodAccessorImpl.java:-2
17/02/16 16:24:08 INFO FileInputFormat: Total input paths to process : 1
17/02/16 16:24:08 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:-2
17/02/16 16:24:08 INFO DAGScheduler: Got job 16 (csv at NativeMethodAccessorImpl.java:-2) with 1 output partitions
17/02/16 16:24:08 INFO DAGScheduler: Final stage: ResultStage 20 (csv at NativeMethodAccessorImpl.java:-2)
17/02/16 16:24:08 INFO DAGScheduler: Parents of final stage: List()
17/02/16 16:24:08 INFO DAGScheduler: Missing parents: List()
17/02/16 16:24:08 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[67] at csv at NativeMethodAccessorImpl.java:-2), which has no missing parents
17/02/16 16:24:08 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 3.3 KB, free 363.6 MB)
17/02/16 16:24:08 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 2029.0 B, free 363.6 MB)
17/02/16 16:24:08 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 127.0.0.1:47988 (size: 2029.0 B, free: 364.3 MB)
17/02/16 16:24:08 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1012
17/02/16 16:24:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[67] at csv at NativeMethodAccessorImpl.java:-2)
17/02/16 16:24:08 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks
17/02/16 16:24:08 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 21, localhost, partition 0, PROCESS_LOCAL, 5453 bytes)
17/02/16 16:24:08 INFO Executor: Running task 0.0 in stage 20.0 (TID 21)
17/02/16 16:24:08 INFO HadoopRDD: Input split: file:/home/vinayak/Desktop/toKaran/Churn_prediction.csv:0+1463648
17/02/16 16:24:08 INFO Executor: Finished task 0.0 in stage 20.0 (TID 21). 1226 bytes result sent to driver
17/02/16 16:24:08 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 21) in 8 ms on localhost (1/1)
17/02/16 16:24:08 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
17/02/16 16:24:08 INFO DAGScheduler: ResultStage 20 (csv at NativeMethodAccessorImpl.java:-2) finished in 0.009 s
17/02/16 16:24:08 INFO DAGScheduler: Job 16 finished: csv at NativeMethodAccessorImpl.java:-2, took 0.015957 s
17/02/16 16:24:08 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:-2
17/02/16 16:24:08 INFO DAGScheduler: Got job 17 (csv at NativeMethodAccessorImpl.java:-2) with 2 output partitions
17/02/16 16:24:08 INFO DAGScheduler: Final stage: ResultStage 21 (csv at NativeMethodAccessorImpl.java:-2)
17/02/16 16:24:08 INFO DAGScheduler: Parents of final stage: List()
17/02/16 16:24:08 INFO DAGScheduler: Missing parents: List()
17/02/16 16:24:08 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[68] at csv at NativeMethodAccessorImpl.java:-2), which has no missing parents
17/02/16 16:24:08 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 5.5 KB, free 363.6 MB)
17/02/16 16:24:08 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 3.2 KB, free 363.6 MB)
17/02/16 16:24:08 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 127.0.0.1:47988 (size: 3.2 KB, free: 364.3 MB)
17/02/16 16:24:08 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1012
17/02/16 16:24:08 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 21 (MapPartitionsRDD[68] at csv at NativeMethodAccessorImpl.java:-2)
17/02/16 16:24:08 INFO TaskSchedulerImpl: Adding task set 21.0 with 2 tasks
17/02/16 16:24:08 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 22, localhost, partition 0, PROCESS_LOCAL, 5457 bytes)
17/02/16 16:24:08 INFO TaskSetManager: Starting task 1.0 in stage 21.0 (TID 23, localhost, partition 1, PROCESS_LOCAL, 5457 bytes)
17/02/16 16:24:08 INFO Executor: Running task 0.0 in stage 21.0 (TID 22)
17/02/16 16:24:08 INFO Executor: Running task 1.0 in stage 21.0 (TID 23)
17/02/16 16:24:08 INFO HadoopRDD: Input split: file:/home/vinayak/Desktop/toKaran/Churn_prediction.csv:0+1463648
17/02/16 16:24:08 INFO HadoopRDD: Input split: file:/home/vinayak/Desktop/toKaran/Churn_prediction.csv:1463648+1463648
17/02/16 16:24:08 INFO Executor: Finished task 1.0 in stage 21.0 (TID 23). 1169 bytes result sent to driver
17/02/16 16:24:08 INFO TaskSetManager: Finished task 1.0 in stage 21.0 (TID 23) in 176 ms on localhost (1/2)
17/02/16 16:24:08 INFO Executor: Finished task 0.0 in stage 21.0 (TID 22). 1169 bytes result sent to driver
17/02/16 16:24:08 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 22) in 181 ms on localhost (2/2)
17/02/16 16:24:08 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
17/02/16 16:24:08 INFO DAGScheduler: ResultStage 21 (csv at NativeMethodAccessorImpl.java:-2) finished in 0.182 s
17/02/16 16:24:08 INFO DAGScheduler: Job 17 finished: csv at NativeMethodAccessorImpl.java:-2, took 0.187893 s
17/02/16 16:24:08 INFO SparkSqlParser: Parsing command: Churn
17/02/16 16:24:08 INFO SparkSqlParser: Parsing command: CACHE TABLE `Churn`
17/02/16 16:24:08 INFO SparkSqlParser: Parsing command: `Churn`
17/02/16 16:24:08 WARN CacheManager: Asked to cache already cached data.
17/02/16 16:24:08 INFO ContextCleaner: Cleaned accumulator 886
17/02/16 16:24:08 INFO ContextCleaner: Cleaned accumulator 887
17/02/16 16:24:08 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 127.0.0.1:47988 in memory (size: 4.4 KB, free: 364.3 MB)
17/02/16 16:24:08 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 127.0.0.1:47988 in memory (size: 22.9 KB, free: 364.3 MB)
17/02/16 16:24:08 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 127.0.0.1:47988 in memory (size: 2029.0 B, free: 364.3 MB)
17/02/16 16:24:08 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 127.0.0.1:47988 in memory (size: 22.9 KB, free: 364.3 MB)
17/02/16 16:24:08 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 127.0.0.1:47988 in memory (size: 2029.0 B, free: 364.4 MB)
17/02/16 16:24:08 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 127.0.0.1:47988 in memory (size: 3.2 KB, free: 364.4 MB)
17/02/16 16:24:08 INFO ContextCleaner: Cleaned accumulator 1086
17/02/16 16:24:08 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:-2
17/02/16 16:24:08 INFO DAGScheduler: Registering RDD 72 (sql at NativeMethodAccessorImpl.java:-2)
17/02/16 16:24:08 INFO DAGScheduler: Got job 18 (sql at NativeMethodAccessorImpl.java:-2) with 1 output partitions
17/02/16 16:24:08 INFO DAGScheduler: Final stage: ResultStage 23 (sql at NativeMethodAccessorImpl.java:-2)
17/02/16 16:24:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 22)
17/02/16 16:24:08 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 22)
17/02/16 16:24:08 INFO DAGScheduler: Submitting ShuffleMapStage 22 (MapPartitionsRDD[72] at sql at NativeMethodAccessorImpl.java:-2), which has no missing parents
17/02/16 16:24:08 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 30.4 KB, free 364.1 MB)
17/02/16 16:24:08 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 11.3 KB, free 364.1 MB)
17/02/16 16:24:08 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 127.0.0.1:47988 (size: 11.3 KB, free: 364.3 MB)
17/02/16 16:24:08 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1012
17/02/16 16:24:08 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 22 (MapPartitionsRDD[72] at sql at NativeMethodAccessorImpl.java:-2)
17/02/16 16:24:08 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks
17/02/16 16:24:08 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 24, localhost, partition 0, PROCESS_LOCAL, 5941 bytes)
17/02/16 16:24:08 INFO Executor: Running task 0.0 in stage 22.0 (TID 24)
17/02/16 16:24:08 INFO BlockManager: Found block rdd_19_0 locally
17/02/16 16:24:08 INFO Executor: Finished task 0.0 in stage 22.0 (TID 24). 2141 bytes result sent to driver
17/02/16 16:24:08 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 24) in 13 ms on localhost (1/1)
17/02/16 16:24:08 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
17/02/16 16:24:08 INFO DAGScheduler: ShuffleMapStage 22 (sql at NativeMethodAccessorImpl.java:-2) finished in 0.014 s
17/02/16 16:24:08 INFO DAGScheduler: looking for newly runnable stages
17/02/16 16:24:08 INFO DAGScheduler: running: Set()
17/02/16 16:24:08 INFO DAGScheduler: waiting: Set(ResultStage 23)
17/02/16 16:24:08 INFO DAGScheduler: failed: Set()
17/02/16 16:24:08 INFO DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[75] at sql at NativeMethodAccessorImpl.java:-2), which has no missing parents
17/02/16 16:24:08 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 7.0 KB, free 364.1 MB)
17/02/16 16:24:08 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 3.7 KB, free 364.1 MB)
17/02/16 16:24:08 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 127.0.0.1:47988 (size: 3.7 KB, free: 364.3 MB)
17/02/16 16:24:08 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1012
17/02/16 16:24:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[75] at sql at NativeMethodAccessorImpl.java:-2)
17/02/16 16:24:08 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks
17/02/16 16:24:08 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 25, localhost, partition 0, ANY, 5345 bytes)
17/02/16 16:24:08 INFO Executor: Running task 0.0 in stage 23.0 (TID 25)
17/02/16 16:24:08 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/02/16 16:24:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/02/16 16:24:08 INFO Executor: Finished task 0.0 in stage 23.0 (TID 25). 1873 bytes result sent to driver
17/02/16 16:24:08 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 25) in 7 ms on localhost (1/1)
17/02/16 16:24:08 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
17/02/16 16:24:08 INFO DAGScheduler: ResultStage 23 (sql at NativeMethodAccessorImpl.java:-2) finished in 0.008 s
17/02/16 16:24:08 INFO DAGScheduler: Job 18 finished: sql at NativeMethodAccessorImpl.java:-2, took 0.035270 s
17/02/16 16:24:08 INFO SparkContext: Starting job: collect at utils.scala:195
17/02/16 16:24:08 INFO DAGScheduler: Got job 19 (collect at utils.scala:195) with 1 output partitions
17/02/16 16:24:08 INFO DAGScheduler: Final stage: ResultStage 24 (collect at utils.scala:195)
17/02/16 16:24:08 INFO DAGScheduler: Parents of final stage: List()
17/02/16 16:24:08 INFO DAGScheduler: Missing parents: List()
17/02/16 16:24:08 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[78] at collect at utils.scala:195), which has no missing parents
17/02/16 16:24:08 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 3.2 KB, free 364.1 MB)
17/02/16 16:24:08 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 1981.0 B, free 364.1 MB)
17/02/16 16:24:08 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 127.0.0.1:47988 (size: 1981.0 B, free: 364.3 MB)
17/02/16 16:24:08 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1012
17/02/16 16:24:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[78] at collect at utils.scala:195)
17/02/16 16:24:08 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks
17/02/16 16:24:08 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 26, localhost, partition 0, PROCESS_LOCAL, 5446 bytes)
17/02/16 16:24:08 INFO Executor: Running task 0.0 in stage 24.0 (TID 26)
17/02/16 16:24:08 INFO Executor: Finished task 0.0 in stage 24.0 (TID 26). 1021 bytes result sent to driver
17/02/16 16:24:08 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 26) in 5 ms on localhost (1/1)
17/02/16 16:24:08 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
17/02/16 16:24:08 INFO DAGScheduler: ResultStage 24 (collect at utils.scala:195) finished in 0.004 s
17/02/16 16:24:08 INFO DAGScheduler: Job 19 finished: collect at utils.scala:195, took 0.012958 s
17/02/16 16:24:08 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `Churn`
17/02/16 16:24:08 INFO SparkSqlParser: Parsing command: count(1)
17/02/16 16:24:08 INFO SparkContext: Starting job: collect at utils.scala:195
17/02/16 16:24:08 INFO DAGScheduler: Registering RDD 81 (collect at utils.scala:195)
17/02/16 16:24:08 INFO DAGScheduler: Got job 20 (collect at utils.scala:195) with 1 output partitions
17/02/16 16:24:08 INFO DAGScheduler: Final stage: ResultStage 26 (collect at utils.scala:195)
17/02/16 16:24:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 25)
17/02/16 16:24:08 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 25)
17/02/16 16:24:08 INFO DAGScheduler: Submitting ShuffleMapStage 25 (MapPartitionsRDD[81] at collect at utils.scala:195), which has no missing parents
17/02/16 16:24:08 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 29.6 KB, free 364.0 MB)
17/02/16 16:24:08 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 11.0 KB, free 364.0 MB)
17/02/16 16:24:08 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 127.0.0.1:47988 (size: 11.0 KB, free: 364.3 MB)
17/02/16 16:24:08 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1012
17/02/16 16:24:08 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 25 (MapPartitionsRDD[81] at collect at utils.scala:195)
17/02/16 16:24:08 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks
17/02/16 16:24:08 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 27, localhost, partition 0, PROCESS_LOCAL, 5933 bytes)
17/02/16 16:24:08 INFO Executor: Running task 0.0 in stage 25.0 (TID 27)
17/02/16 16:24:08 INFO BlockManager: Found block rdd_19_0 locally
17/02/16 16:24:08 INFO Executor: Finished task 0.0 in stage 25.0 (TID 27). 2141 bytes result sent to driver
17/02/16 16:24:08 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 27) in 17 ms on localhost (1/1)
17/02/16 16:24:08 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
17/02/16 16:24:08 INFO DAGScheduler: ShuffleMapStage 25 (collect at utils.scala:195) finished in 0.017 s
17/02/16 16:24:08 INFO DAGScheduler: looking for newly runnable stages
17/02/16 16:24:08 INFO DAGScheduler: running: Set()
17/02/16 16:24:08 INFO DAGScheduler: waiting: Set(ResultStage 26)
17/02/16 16:24:08 INFO DAGScheduler: failed: Set()
17/02/16 16:24:08 INFO DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[84] at collect at utils.scala:195), which has no missing parents
17/02/16 16:24:08 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 9.5 KB, free 364.0 MB)
17/02/16 16:24:08 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 4.1 KB, free 364.0 MB)
17/02/16 16:24:08 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 127.0.0.1:47988 (size: 4.1 KB, free: 364.3 MB)
17/02/16 16:24:08 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1012
17/02/16 16:24:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (MapPartitionsRDD[84] at collect at utils.scala:195)
17/02/16 16:24:08 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks
17/02/16 16:24:08 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 28, localhost, partition 0, ANY, 5337 bytes)
17/02/16 16:24:08 INFO Executor: Running task 0.0 in stage 26.0 (TID 28)
17/02/16 16:24:08 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/02/16 16:24:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/02/16 16:24:08 INFO Executor: Finished task 0.0 in stage 26.0 (TID 28). 2189 bytes result sent to driver
17/02/16 16:24:08 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 28) in 7 ms on localhost (1/1)
17/02/16 16:24:08 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
17/02/16 16:24:08 INFO DAGScheduler: ResultStage 26 (collect at utils.scala:195) finished in 0.006 s
17/02/16 16:24:08 INFO DAGScheduler: Job 20 finished: collect at utils.scala:195, took 0.038557 s
17/02/16 16:24:08 INFO SparkSqlParser: Parsing command: SELECT *
FROM `Churn` AS `zzz2`
WHERE (0 = 1)
17/02/16 16:24:08 INFO SparkSqlParser: Parsing command: ID
17/02/16 16:24:08 INFO SparkSqlParser: Parsing command: CreditLimit
17/02/16 16:24:08 INFO SparkSqlParser: Parsing command: Sex
17/02/16 16:24:08 INFO SparkSqlParser: Parsing command: Education
17/02/16 16:24:08 INFO SparkSqlParser: Parsing command: MaritalStatus
17/02/16 16:24:08 INFO SparkSqlParser: Parsing command: Age
17/02/16 16:24:08 INFO SparkSqlParser: Parsing command: RPStatusSep
17/02/16 16:24:08 INFO SparkSqlParser: Parsing command: RPStatusAug
17/02/16 16:24:08 INFO SparkSqlParser: Parsing command: RPStatusJuly
17/02/16 16:24:08 INFO SparkSqlParser: Parsing command: RPStatusJune
17/02/16 16:24:08 INFO SparkSqlParser: Parsing command: RPStatusMay
17/02/16 16:24:08 INFO SparkSqlParser: Parsing command: RPStatusApril
17/02/16 16:24:08 INFO SparkSqlParser: Parsing command: BILL_AMT_Sept
17/02/16 16:24:08 INFO SparkSqlParser: Parsing command: BILL_AMT_August
17/02/16 16:24:08 INFO SparkSqlParser: Parsing command: BILL_AMT_July
17/02/16 16:24:08 INFO SparkSqlParser: Parsing command: BILL_AMT_June
17/02/16 16:24:08 INFO SparkSqlParser: Parsing command: BILL_AMT_May
17/02/16 16:24:08 INFO SparkSqlParser: Parsing command: BILL_AMT_April
17/02/16 16:24:08 INFO SparkSqlParser: Parsing command: PAY_AMT_Sept
17/02/16 16:24:08 INFO SparkSqlParser: Parsing command: PAY_AMT_August
17/02/16 16:24:08 INFO SparkSqlParser: Parsing command: PAY_AMT_July
17/02/16 16:24:08 INFO SparkSqlParser: Parsing command: PAY_AMT_June
17/02/16 16:24:08 INFO SparkSqlParser: Parsing command: PAY_AMT_May
17/02/16 16:24:08 INFO SparkSqlParser: Parsing command: PAY_AMT_April
17/02/16 16:24:08 INFO SparkSqlParser: Parsing command: default
17/02/16 16:24:08 INFO SparkSqlParser: Parsing command: message
17/02/16 16:24:08 INFO SparkSqlParser: Parsing command: SELECT *
FROM `Churn`
17/02/16 16:24:08 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:-2
17/02/16 16:24:08 INFO DAGScheduler: Registering RDD 87 (count at NativeMethodAccessorImpl.java:-2)
17/02/16 16:24:08 INFO DAGScheduler: Got job 21 (count at NativeMethodAccessorImpl.java:-2) with 1 output partitions
17/02/16 16:24:08 INFO DAGScheduler: Final stage: ResultStage 28 (count at NativeMethodAccessorImpl.java:-2)
17/02/16 16:24:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 27)
17/02/16 16:24:08 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 27)
17/02/16 16:24:08 INFO DAGScheduler: Submitting ShuffleMapStage 27 (MapPartitionsRDD[87] at count at NativeMethodAccessorImpl.java:-2), which has no missing parents
17/02/16 16:24:08 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 30.4 KB, free 364.0 MB)
17/02/16 16:24:08 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 11.3 KB, free 364.0 MB)
17/02/16 16:24:08 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 127.0.0.1:47988 (size: 11.3 KB, free: 364.3 MB)
17/02/16 16:24:08 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1012
17/02/16 16:24:08 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 27 (MapPartitionsRDD[87] at count at NativeMethodAccessorImpl.java:-2)
17/02/16 16:24:08 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks
17/02/16 16:24:08 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 29, localhost, partition 0, PROCESS_LOCAL, 5933 bytes)
17/02/16 16:24:08 INFO Executor: Running task 0.0 in stage 27.0 (TID 29)
17/02/16 16:24:08 INFO BlockManager: Found block rdd_19_0 locally
17/02/16 16:24:08 INFO Executor: Finished task 0.0 in stage 27.0 (TID 29). 2141 bytes result sent to driver
17/02/16 16:24:08 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 29) in 11 ms on localhost (1/1)
17/02/16 16:24:08 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
17/02/16 16:24:08 INFO DAGScheduler: ShuffleMapStage 27 (count at NativeMethodAccessorImpl.java:-2) finished in 0.011 s
17/02/16 16:24:08 INFO DAGScheduler: looking for newly runnable stages
17/02/16 16:24:08 INFO DAGScheduler: running: Set()
17/02/16 16:24:08 INFO DAGScheduler: waiting: Set(ResultStage 28)
17/02/16 16:24:08 INFO DAGScheduler: failed: Set()
17/02/16 16:24:08 INFO DAGScheduler: Submitting ResultStage 28 (MapPartitionsRDD[90] at count at NativeMethodAccessorImpl.java:-2), which has no missing parents
17/02/16 16:24:08 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 7.0 KB, free 364.0 MB)
17/02/16 16:24:08 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 3.7 KB, free 364.0 MB)
17/02/16 16:24:08 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 127.0.0.1:47988 (size: 3.7 KB, free: 364.3 MB)
17/02/16 16:24:08 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1012
17/02/16 16:24:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 28 (MapPartitionsRDD[90] at count at NativeMethodAccessorImpl.java:-2)
17/02/16 16:24:08 INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks
17/02/16 16:24:08 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 30, localhost, partition 0, ANY, 5337 bytes)
17/02/16 16:24:08 INFO Executor: Running task 0.0 in stage 28.0 (TID 30)
17/02/16 16:24:08 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/02/16 16:24:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/02/16 16:24:08 INFO Executor: Finished task 0.0 in stage 28.0 (TID 30). 1873 bytes result sent to driver
17/02/16 16:24:08 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 30) in 6 ms on localhost (1/1)
17/02/16 16:24:08 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
17/02/16 16:24:08 INFO DAGScheduler: ResultStage 28 (count at NativeMethodAccessorImpl.java:-2) finished in 0.006 s
17/02/16 16:24:08 INFO DAGScheduler: Job 21 finished: count at NativeMethodAccessorImpl.java:-2, took 0.031070 s
17/02/16 16:24:08 INFO SparkSqlParser: Parsing command: SELECT *
FROM `Churn`
17/02/16 16:24:08 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:-2
17/02/16 16:24:08 INFO DAGScheduler: Registering RDD 93 (count at NativeMethodAccessorImpl.java:-2)
17/02/16 16:24:08 INFO DAGScheduler: Got job 22 (count at NativeMethodAccessorImpl.java:-2) with 1 output partitions
17/02/16 16:24:08 INFO DAGScheduler: Final stage: ResultStage 30 (count at NativeMethodAccessorImpl.java:-2)
17/02/16 16:24:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 29)
17/02/16 16:24:08 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 29)
17/02/16 16:24:08 INFO DAGScheduler: Submitting ShuffleMapStage 29 (MapPartitionsRDD[93] at count at NativeMethodAccessorImpl.java:-2), which has no missing parents
17/02/16 16:24:08 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 30.4 KB, free 363.9 MB)
17/02/16 16:24:08 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 11.3 KB, free 363.9 MB)
17/02/16 16:24:08 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 127.0.0.1:47988 (size: 11.3 KB, free: 364.3 MB)
17/02/16 16:24:08 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1012
17/02/16 16:24:08 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 29 (MapPartitionsRDD[93] at count at NativeMethodAccessorImpl.java:-2)
17/02/16 16:24:08 INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks
17/02/16 16:24:08 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 31, localhost, partition 0, PROCESS_LOCAL, 5933 bytes)
17/02/16 16:24:08 INFO Executor: Running task 0.0 in stage 29.0 (TID 31)
17/02/16 16:24:08 INFO BlockManager: Found block rdd_19_0 locally
17/02/16 16:24:08 INFO Executor: Finished task 0.0 in stage 29.0 (TID 31). 2141 bytes result sent to driver
17/02/16 16:24:08 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 31) in 17 ms on localhost (1/1)
17/02/16 16:24:08 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
17/02/16 16:24:08 INFO DAGScheduler: ShuffleMapStage 29 (count at NativeMethodAccessorImpl.java:-2) finished in 0.018 s
17/02/16 16:24:08 INFO DAGScheduler: looking for newly runnable stages
17/02/16 16:24:08 INFO DAGScheduler: running: Set()
17/02/16 16:24:08 INFO DAGScheduler: waiting: Set(ResultStage 30)
17/02/16 16:24:08 INFO DAGScheduler: failed: Set()
17/02/16 16:24:08 INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[96] at count at NativeMethodAccessorImpl.java:-2), which has no missing parents
17/02/16 16:24:08 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 7.0 KB, free 363.9 MB)
17/02/16 16:24:08 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 3.7 KB, free 363.9 MB)
17/02/16 16:24:08 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 127.0.0.1:47988 (size: 3.7 KB, free: 364.3 MB)
17/02/16 16:24:08 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1012
17/02/16 16:24:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 30 (MapPartitionsRDD[96] at count at NativeMethodAccessorImpl.java:-2)
17/02/16 16:24:08 INFO TaskSchedulerImpl: Adding task set 30.0 with 1 tasks
17/02/16 16:24:08 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 32, localhost, partition 0, ANY, 5337 bytes)
17/02/16 16:24:08 INFO Executor: Running task 0.0 in stage 30.0 (TID 32)
17/02/16 16:24:08 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/02/16 16:24:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/02/16 16:24:08 INFO Executor: Finished task 0.0 in stage 30.0 (TID 32). 1873 bytes result sent to driver
17/02/16 16:24:08 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 32) in 5 ms on localhost (1/1)
17/02/16 16:24:08 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
17/02/16 16:24:08 INFO DAGScheduler: ResultStage 30 (count at NativeMethodAccessorImpl.java:-2) finished in 0.005 s
17/02/16 16:24:08 INFO DAGScheduler: Job 22 finished: count at NativeMethodAccessorImpl.java:-2, took 0.037922 s
17/02/16 16:24:08 INFO SparkSqlParser: Parsing command: SELECT *
FROM `Churn`
LIMIT 10
17/02/16 16:24:08 INFO SparkSqlParser: Parsing command: ID
17/02/16 16:24:08 INFO SparkSqlParser: Parsing command: CreditLimit
17/02/16 16:24:08 INFO SparkSqlParser: Parsing command: Sex
17/02/16 16:24:08 INFO SparkSqlParser: Parsing command: Education
17/02/16 16:24:08 INFO SparkSqlParser: Parsing command: MaritalStatus
17/02/16 16:24:08 INFO SparkSqlParser: Parsing command: Age
17/02/16 16:24:08 INFO SparkSqlParser: Parsing command: RPStatusSep
17/02/16 16:24:08 INFO SparkSqlParser: Parsing command: RPStatusAug
17/02/16 16:24:08 INFO SparkSqlParser: Parsing command: RPStatusJuly
17/02/16 16:24:08 INFO SparkSqlParser: Parsing command: RPStatusJune
17/02/16 16:24:08 INFO SparkSqlParser: Parsing command: RPStatusMay
17/02/16 16:24:08 INFO SparkSqlParser: Parsing command: RPStatusApril
17/02/16 16:24:08 INFO SparkSqlParser: Parsing command: BILL_AMT_Sept
17/02/16 16:24:08 INFO SparkSqlParser: Parsing command: BILL_AMT_August
17/02/16 16:24:08 INFO SparkSqlParser: Parsing command: BILL_AMT_July
17/02/16 16:24:08 INFO SparkSqlParser: Parsing command: BILL_AMT_June
17/02/16 16:24:08 INFO SparkSqlParser: Parsing command: BILL_AMT_May
17/02/16 16:24:08 INFO SparkSqlParser: Parsing command: BILL_AMT_April
17/02/16 16:24:08 INFO SparkSqlParser: Parsing command: PAY_AMT_Sept
17/02/16 16:24:08 INFO SparkSqlParser: Parsing command: PAY_AMT_August
17/02/16 16:24:08 INFO SparkSqlParser: Parsing command: PAY_AMT_July
17/02/16 16:24:08 INFO SparkSqlParser: Parsing command: PAY_AMT_June
17/02/16 16:24:08 INFO SparkSqlParser: Parsing command: PAY_AMT_May
17/02/16 16:24:08 INFO SparkSqlParser: Parsing command: PAY_AMT_April
17/02/16 16:24:08 INFO SparkSqlParser: Parsing command: default
17/02/16 16:24:08 INFO SparkSqlParser: Parsing command: message
17/02/16 16:24:08 INFO SparkContext: Starting job: collect at utils.scala:195
17/02/16 16:24:08 INFO DAGScheduler: Got job 23 (collect at utils.scala:195) with 1 output partitions
17/02/16 16:24:08 INFO DAGScheduler: Final stage: ResultStage 31 (collect at utils.scala:195)
17/02/16 16:24:08 INFO DAGScheduler: Parents of final stage: List()
17/02/16 16:24:08 INFO DAGScheduler: Missing parents: List()
17/02/16 16:24:08 INFO DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[98] at collect at utils.scala:195), which has no missing parents
17/02/16 16:24:08 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 26.6 KB, free 363.9 MB)
17/02/16 16:24:08 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 9.9 KB, free 363.9 MB)
17/02/16 16:24:08 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 127.0.0.1:47988 (size: 9.9 KB, free: 364.3 MB)
17/02/16 16:24:08 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1012
17/02/16 16:24:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[98] at collect at utils.scala:195)
17/02/16 16:24:08 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks
17/02/16 16:24:08 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 33, localhost, partition 0, PROCESS_LOCAL, 5858 bytes)
17/02/16 16:24:08 INFO Executor: Running task 0.0 in stage 31.0 (TID 33)
17/02/16 16:24:08 INFO BlockManager: Found block rdd_19_0 locally
17/02/16 16:24:08 WARN Executor: 1 block locks were not released by TID = 33:
[rdd_19_0]
17/02/16 16:24:08 INFO Executor: Finished task 0.0 in stage 31.0 (TID 33). 2409 bytes result sent to driver
17/02/16 16:24:08 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 33) in 10 ms on localhost (1/1)
17/02/16 16:24:08 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
17/02/16 16:24:08 INFO DAGScheduler: ResultStage 31 (collect at utils.scala:195) finished in 0.012 s
17/02/16 16:24:08 INFO DAGScheduler: Job 23 finished: collect at utils.scala:195, took 0.027713 s
17/02/16 16:24:09 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/02/16 16:24:09 INFO HiveMetaStore: 0: get_database: default
17/02/16 16:24:09 INFO audit: ugi=vinayak	ip=unknown-ip-addr	cmd=get_database: default	
17/02/16 16:24:09 INFO HiveMetaStore: 0: get_database: default
17/02/16 16:24:09 INFO audit: ugi=vinayak	ip=unknown-ip-addr	cmd=get_database: default	
17/02/16 16:24:09 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/02/16 16:24:09 INFO audit: ugi=vinayak	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/02/16 16:24:09 INFO SparkSqlParser: Parsing command: tableName
17/02/16 16:24:09 INFO SparkSqlParser: Parsing command: isTemporary
17/02/16 16:24:09 INFO SparkContext: Starting job: collect at utils.scala:195
17/02/16 16:24:09 INFO DAGScheduler: Got job 24 (collect at utils.scala:195) with 1 output partitions
17/02/16 16:24:09 INFO DAGScheduler: Final stage: ResultStage 32 (collect at utils.scala:195)
17/02/16 16:24:09 INFO DAGScheduler: Parents of final stage: List()
17/02/16 16:24:09 INFO DAGScheduler: Missing parents: List()
17/02/16 16:24:09 INFO DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[101] at collect at utils.scala:195), which has no missing parents
17/02/16 16:24:09 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 4.0 KB, free 363.9 MB)
17/02/16 16:24:09 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 2.5 KB, free 363.9 MB)
17/02/16 16:24:09 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 127.0.0.1:47988 (size: 2.5 KB, free: 364.3 MB)
17/02/16 16:24:09 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1012
17/02/16 16:24:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[101] at collect at utils.scala:195)
17/02/16 16:24:09 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks
17/02/16 16:24:09 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 34, localhost, partition 0, PROCESS_LOCAL, 5715 bytes)
17/02/16 16:24:09 INFO Executor: Running task 0.0 in stage 32.0 (TID 34)
17/02/16 16:24:09 INFO Executor: Finished task 0.0 in stage 32.0 (TID 34). 1050 bytes result sent to driver
17/02/16 16:24:09 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 34) in 5 ms on localhost (1/1)
17/02/16 16:24:09 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
17/02/16 16:24:09 INFO DAGScheduler: ResultStage 32 (collect at utils.scala:195) finished in 0.006 s
17/02/16 16:24:09 INFO DAGScheduler: Job 24 finished: collect at utils.scala:195, took 0.011214 s
17/02/16 16:53:55 INFO ContextCleaner: Cleaned accumulator 1450
17/02/16 16:53:55 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 127.0.0.1:47988 in memory (size: 11.0 KB, free: 364.3 MB)
17/02/16 16:53:55 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 127.0.0.1:47988 in memory (size: 4.1 KB, free: 364.3 MB)
17/02/16 16:53:55 INFO ContextCleaner: Cleaned accumulator 1342
17/02/16 16:53:55 INFO ContextCleaner: Cleaned accumulator 1343
17/02/16 16:53:55 INFO ContextCleaner: Cleaned accumulator 1344
17/02/16 16:53:55 INFO ContextCleaner: Cleaned accumulator 1345
17/02/16 16:53:55 INFO ContextCleaner: Cleaned accumulator 1346
17/02/16 16:53:55 INFO ContextCleaner: Cleaned accumulator 1347
17/02/16 16:53:55 INFO ContextCleaner: Cleaned accumulator 1348
17/02/16 16:53:55 INFO ContextCleaner: Cleaned accumulator 1349
17/02/16 16:53:55 INFO ContextCleaner: Cleaned accumulator 1350
17/02/16 16:53:55 INFO ContextCleaner: Cleaned accumulator 1351
17/02/16 16:53:55 INFO ContextCleaner: Cleaned accumulator 1352
17/02/16 16:53:55 INFO ContextCleaner: Cleaned accumulator 1353
17/02/16 16:53:55 INFO ContextCleaner: Cleaned accumulator 1354
17/02/16 16:53:55 INFO ContextCleaner: Cleaned shuffle 6
17/02/16 16:53:55 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 127.0.0.1:47988 in memory (size: 11.3 KB, free: 364.3 MB)
17/02/16 16:53:55 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 127.0.0.1:47988 in memory (size: 3.7 KB, free: 364.3 MB)
17/02/16 16:53:55 INFO ContextCleaner: Cleaned accumulator 1443
17/02/16 16:53:55 INFO ContextCleaner: Cleaned accumulator 1444
17/02/16 16:53:55 INFO ContextCleaner: Cleaned accumulator 1445
17/02/16 16:53:55 INFO ContextCleaner: Cleaned accumulator 1446
17/02/16 16:53:55 INFO ContextCleaner: Cleaned accumulator 1447
17/02/16 16:53:55 INFO ContextCleaner: Cleaned accumulator 1448
17/02/16 16:53:55 INFO ContextCleaner: Cleaned accumulator 1449
17/02/16 16:53:55 INFO ContextCleaner: Cleaned accumulator 1451
17/02/16 16:53:55 INFO ContextCleaner: Cleaned accumulator 1452
17/02/16 16:53:55 INFO ContextCleaner: Cleaned accumulator 1453
17/02/16 16:53:55 INFO ContextCleaner: Cleaned accumulator 1454
17/02/16 16:53:55 INFO ContextCleaner: Cleaned accumulator 1455
17/02/16 16:53:55 INFO ContextCleaner: Cleaned shuffle 7
17/02/16 16:53:55 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 127.0.0.1:47988 in memory (size: 11.3 KB, free: 364.3 MB)
17/02/16 16:53:55 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 127.0.0.1:47988 in memory (size: 3.7 KB, free: 364.3 MB)
17/02/16 16:53:56 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 127.0.0.1:47988 in memory (size: 9.9 KB, free: 364.3 MB)
17/02/16 16:53:56 INFO ContextCleaner: Cleaned accumulator 1087
17/02/16 16:53:56 INFO ContextCleaner: Cleaned accumulator 1088
17/02/16 16:53:56 INFO ContextCleaner: Cleaned accumulator 1089
17/02/16 16:53:56 INFO ContextCleaner: Cleaned accumulator 1090
17/02/16 16:53:56 INFO ContextCleaner: Cleaned accumulator 1091
17/02/16 16:53:56 INFO ContextCleaner: Cleaned accumulator 1092
17/02/16 16:53:56 INFO ContextCleaner: Cleaned accumulator 1093
17/02/16 16:53:56 INFO ContextCleaner: Cleaned accumulator 1094
17/02/16 16:53:56 INFO ContextCleaner: Cleaned accumulator 1095
17/02/16 16:53:56 INFO ContextCleaner: Cleaned accumulator 1096
17/02/16 16:53:56 INFO ContextCleaner: Cleaned accumulator 1097
17/02/16 16:53:56 INFO ContextCleaner: Cleaned accumulator 1098
17/02/16 16:53:56 INFO ContextCleaner: Cleaned shuffle 4
17/02/16 16:53:56 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 127.0.0.1:47988 in memory (size: 11.3 KB, free: 364.3 MB)
17/02/16 16:53:56 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 127.0.0.1:47988 in memory (size: 3.7 KB, free: 364.3 MB)
17/02/16 16:53:56 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 127.0.0.1:47988 in memory (size: 1981.0 B, free: 364.4 MB)
17/02/16 16:53:56 INFO ContextCleaner: Cleaned accumulator 1232
17/02/16 16:53:56 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 127.0.0.1:47988 in memory (size: 2.5 KB, free: 364.4 MB)
